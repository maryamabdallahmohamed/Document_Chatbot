{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92876b39",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a52a1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import faiss\n",
    "import time\n",
    "import yaml\n",
    "import re\n",
    "from pathlib import Path\n",
    "from abc import ABC, abstractmethod\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.llms import Ollama\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e068f9",
   "metadata": {},
   "source": [
    "## Abstract classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2b30a8",
   "metadata": {},
   "source": [
    "### Preprocessing class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7caedd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class BasePreprocessor(ABC):\n",
    "    def __init__(self):\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=200,\n",
    "            chunk_overlap=50, \n",
    "            length_function=lambda x: len(x.split()),\n",
    "            separators=[\"\\n\\n\\n\", \"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \"; \", \", \", \" \", \"\"],\n",
    "            keep_separator=False,\n",
    "            add_start_index=True,\n",
    "            strip_whitespace=True\n",
    "        )\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_and_preprocess_data(self, file_path):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def process_documents_from_files(self, file_paths):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        return re.sub(r'\\s+', ' ', re.sub(r'\\n{3,}', '\\n\\n', str(text))).strip()\n",
    "\n",
    "\n",
    "\n",
    "    def chunk_documents(self, individual_documents):\n",
    "        chunked_docs = []\n",
    "        for doc in individual_documents:\n",
    "            chunks = self.text_splitter.split_text(doc.page_content)\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                chunked_docs.append(\n",
    "                    Document(\n",
    "                        page_content=chunk,\n",
    "                        metadata={\n",
    "                            \"pdf_id\": doc.metadata[\"pdf_id\"],\n",
    "                            \"chunk_id\": i\n",
    "                        }\n",
    "                    )\n",
    "                )\n",
    "        print(f\"✅ Total Chunks: {len(chunked_docs)}\")\n",
    "        return chunked_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23e66d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSONPreprocessor(BasePreprocessor):\n",
    "    def load_and_preprocess_data(self, file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            raw_data = json.load(f)\n",
    "        clean_texts = [self.clean_text(entry) for entry in raw_data if isinstance(entry, str)]\n",
    "        return \"\\n\".join(clean_texts)\n",
    "    def process_documents_from_files(self, file_paths):\n",
    "        documents = []\n",
    "\n",
    "        for i, file_path in enumerate(file_paths):\n",
    "            text = self.load_and_preprocess_data(file_path).strip()\n",
    "            documents.append(\n",
    "                Document(page_content=text, metadata={\"pdf_id\": i})\n",
    "            )\n",
    "\n",
    "        return documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c8bf9b",
   "metadata": {},
   "source": [
    "### Embeddings Abstract class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80805382",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(ABC): \n",
    "    def __init__(self, model_name, batch_size):\n",
    "        self.model_name = model_name\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.device = (\n",
    "            'cuda' if torch.cuda.is_available()\n",
    "            else 'mps' if torch.backends.mps.is_available()\n",
    "            else 'cpu'\n",
    "        )\n",
    "        self.embedding_model = HuggingFaceEmbeddings(model_name=model_name,model_kwargs={'device': self.device},encode_kwargs={'normalize_embeddings': True},multi_process=True,\n",
    "                                                     show_progress=True,cache_folder='./embedder_model_cache')\n",
    "\n",
    "    @abstractmethod\n",
    "    def embed_documents(self, documents):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def batch_embed(self, texts, batch_size=None): \n",
    "        pass\n",
    "\n",
    "class MultilingualEmbedder(Embedder): \n",
    "    def __init__(self, model_name, batch_size):\n",
    "        super().__init__(model_name, batch_size)\n",
    "\n",
    "    def embed_documents(self, documents):\n",
    "        return self.batch_embed(documents, batch_size=self.batch_size)\n",
    "\n",
    "    def batch_embed(self, texts, batch_size=None):\n",
    "        if batch_size is None:\n",
    "            batch_size = self.batch_size\n",
    "        \n",
    "        embeddings = []\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i + batch_size]\n",
    "            batch_embeddings = self.embedding_model.embed_documents(batch)\n",
    "            embeddings.extend(batch_embeddings)\n",
    "        \n",
    "        return np.array(embeddings, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22818acf",
   "metadata": {},
   "source": [
    "### Faiss Abstract class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89195008",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStoreBase(ABC):\n",
    "    @abstractmethod\n",
    "    def create_vector_store(self, documents, embedder_model):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_relevant_documents(self, query, top_k=5):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def save_index(self, file_path):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def load_index(self, file_path):\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1ce8c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FAISSBasic(VectorStoreBase):\n",
    "    def __init__(self, embedder_model=None):\n",
    "        self.index = None\n",
    "        self.chunks_dict = None\n",
    "        self.dimension = None\n",
    "        self.total_vectors = 0\n",
    "        self.index_type = \"IndexFlatIP\"\n",
    "        self.embedder_model = embedder_model\n",
    "    \n",
    "    def create_vector_store(self, documents, embedder_model=None):\n",
    "        \"\"\"Create vector store from documents\"\"\"\n",
    "        if embedder_model:\n",
    "            self.embedder_model = embedder_model\n",
    "        \n",
    "        if not self.embedder_model:\n",
    "            raise ValueError(\"Embedder model is required\")\n",
    "        \n",
    "        texts = [doc.page_content for doc in documents]\n",
    "        embeddings = self.embedder_model.batch_embed(texts)\n",
    "        embeddings = np.array(embeddings).astype(\"float32\")\n",
    "        \n",
    "        # Ensure embeddings are 2D\n",
    "        if embeddings.ndim == 1:\n",
    "            embeddings = embeddings.reshape(1, -1)\n",
    "        \n",
    "        self.dimension = embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatIP(self.dimension)\n",
    "        self.index.add(embeddings)\n",
    "        \n",
    "        # Store text chunks with their indices\n",
    "        self.chunks_dict = {i: text for i, text in enumerate(texts)}\n",
    "        self.total_vectors = self.index.ntotal\n",
    "        \n",
    "        print(f\"[FAISS] Created index with {self.total_vectors} vectors of dim {self.dimension}\")\n",
    "        return self\n",
    "    \n",
    "    def get_relevant_documents(self, query, top_k=5):\n",
    "        \"\"\"Main retriever function - returns LangChain Document objects\"\"\"\n",
    "        if self.index is None:\n",
    "            raise ValueError(\"Index not created. Call create_vector_store() first.\")\n",
    "        \n",
    "        if not self.embedder_model:\n",
    "            raise ValueError(\"Embedder model not set\")\n",
    "        \n",
    "        # Get query embedding\n",
    "        if isinstance(query, str):\n",
    "            query_embedding = self.embedder_model.batch_embed([query])\n",
    "            if isinstance(query_embedding, list) and len(query_embedding) > 0:\n",
    "                query_embedding = query_embedding[0]\n",
    "            elif isinstance(query_embedding, np.ndarray) and query_embedding.ndim > 1:\n",
    "                query_embedding = query_embedding[0]\n",
    "        else:\n",
    "            query_embedding = self.embedder_model.batch_embed(query)\n",
    "        \n",
    "        # Search and format results\n",
    "        results = self._search_chunks(query_embedding, top_k)\n",
    "        \n",
    "        return [\n",
    "            Document(page_content=res['text'], metadata={\"similarity\": res['similarity']})\n",
    "            for res in results\n",
    "        ]\n",
    "    \n",
    "    def _search_chunks(self, query_embedding, top_k=5):\n",
    "        \"\"\"Internal search function - returns raw results\"\"\"\n",
    "        # Ensure query_embedding is properly shaped\n",
    "        query_embedding = np.array(query_embedding).astype(\"float32\")\n",
    "        \n",
    "        # Handle different input shapes\n",
    "        if query_embedding.ndim == 1:\n",
    "            query_embedding = query_embedding.reshape(1, -1)\n",
    "        elif query_embedding.ndim > 2:\n",
    "            query_embedding = query_embedding.reshape(1, -1)\n",
    "        \n",
    "        print(f\"[DEBUG] Query embedding final shape: {query_embedding.shape}\")\n",
    "        print(f\"[DEBUG] Index dimension: {self.dimension}\")\n",
    "        \n",
    "        # Verify dimensions match\n",
    "        if query_embedding.shape[1] != self.dimension:\n",
    "            raise ValueError(f\"Query embedding dimension {query_embedding.shape[1]} doesn't match index dimension {self.dimension}\")\n",
    "        \n",
    "        # Search FAISS index\n",
    "        distances, indices = self.index.search(query_embedding, top_k)\n",
    "        \n",
    "        # Format results\n",
    "        formatted = []\n",
    "        for i in range(top_k):\n",
    "            faiss_idx = indices[0][i]\n",
    "            if faiss_idx != -1 and faiss_idx < len(self.chunks_dict):\n",
    "                distance = distances[0][i]\n",
    "                formatted.append({\n",
    "                    'chunk_id': faiss_idx,\n",
    "                    'text': self.chunks_dict[faiss_idx],\n",
    "                    'distance': distance,\n",
    "                    'similarity': float(distance) \n",
    "                })\n",
    "        \n",
    "        return formatted\n",
    "    \n",
    "    def search_raw(self, query_embedding, top_k=5):\n",
    "        \"\"\"Search with raw embedding input - useful for advanced use cases\"\"\"\n",
    "        return self._search_chunks(query_embedding, top_k)\n",
    "    \n",
    "    def save_index(self, file_path):\n",
    "        \"\"\"Save both FAISS index and metadata\"\"\"\n",
    "        if self.index is None:\n",
    "            raise ValueError(\"No index to save\")\n",
    "        \n",
    "        # Save FAISS index\n",
    "        faiss.write_index(self.index, f\"{file_path}.faiss\")\n",
    "        \n",
    "        # Save metadata\n",
    "        metadata = {\n",
    "            'chunks_dict': self.chunks_dict,\n",
    "            'dimension': self.dimension,\n",
    "            'total_vectors': self.total_vectors,\n",
    "            'index_type': self.index_type\n",
    "        }\n",
    "        \n",
    "        with open(f\"{file_path}_metadata.pkl\", 'wb') as f:\n",
    "            pickle.dump(metadata, f)\n",
    "        \n",
    "        print(f\"[FAISS] Index and metadata saved to {file_path}\")\n",
    "    \n",
    "    def load_index(self, file_path, embedder_model=None):\n",
    "        \"\"\"Load both FAISS index and metadata\"\"\"\n",
    "        if not os.path.exists(f\"{file_path}.faiss\"):\n",
    "            raise FileNotFoundError(f\"Index file {file_path}.faiss not found\")\n",
    "        \n",
    "        if not os.path.exists(f\"{file_path}_metadata.pkl\"):\n",
    "            raise FileNotFoundError(f\"Metadata file {file_path}_metadata.pkl not found\")\n",
    "        \n",
    "        # Load FAISS index\n",
    "        self.index = faiss.read_index(f\"{file_path}.faiss\")\n",
    "        \n",
    "        # Load metadata\n",
    "        with open(f\"{file_path}_metadata.pkl\", 'rb') as f:\n",
    "            metadata = pickle.load(f)\n",
    "        \n",
    "        self.chunks_dict = metadata['chunks_dict']\n",
    "        self.dimension = metadata['dimension']\n",
    "        self.total_vectors = metadata['total_vectors']\n",
    "        self.index_type = metadata['index_type']\n",
    "        \n",
    "        # Set embedder model if provided\n",
    "        if embedder_model:\n",
    "            self.embedder_model = embedder_model\n",
    "        \n",
    "        print(f\"[FAISS] Index loaded: {self.total_vectors} vectors, dim {self.dimension}\")\n",
    "        return self\n",
    "    \n",
    "    def set_embedder_model(self, embedder_model):\n",
    "        \"\"\"Set or update the embedder model\"\"\"\n",
    "        self.embedder_model = embedder_model\n",
    "        return self\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get index statistics\"\"\"\n",
    "        return {\n",
    "            'total_vectors': self.total_vectors,\n",
    "            'dimension': self.dimension,\n",
    "            'index_type': self.index_type,\n",
    "            'has_embedder': self.embedder_model is not None\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ed1060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FAISSImproved(VectorStoreBase):\n",
    "    def __init__(self, embedder_model=None):\n",
    "        self.index = None\n",
    "        self.chunks_dict = None\n",
    "        self.dimension = None\n",
    "        self.total_vectors = 0\n",
    "        self.index_type = \"IndexFlatIP\"\n",
    "        self.embedder_model = embedder_model\n",
    "        # New attributes for enhanced functionality\n",
    "        self.docstore = None\n",
    "        self.index_to_docstore_id = None\n",
    "        self.documents = None  # Store original Document objects\n",
    "    \n",
    "    def create_vector_store(self, documents, embedder_model=None):\n",
    "        \"\"\"Create vector store from documents\"\"\"\n",
    "        if embedder_model:\n",
    "            self.embedder_model = embedder_model\n",
    "        \n",
    "        if not self.embedder_model:\n",
    "            raise ValueError(\"Embedder model is required\")\n",
    "        \n",
    "        texts = [doc.page_content for doc in documents]\n",
    "        embeddings = self.embedder_model.batch_embed(texts)\n",
    "        embeddings = np.array(embeddings).astype(\"float32\")\n",
    "        \n",
    "        # Ensure embeddings are 2D\n",
    "        if embeddings.ndim == 1:\n",
    "            embeddings = embeddings.reshape(1, -1)\n",
    "        \n",
    "        self.dimension = embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatIP(self.dimension)\n",
    "        self.index.add(embeddings)\n",
    "        \n",
    "        # Store text chunks with their indices\n",
    "        self.chunks_dict = {i: text for i, text in enumerate(texts)}\n",
    "        self.total_vectors = self.index.ntotal\n",
    "        \n",
    "        print(f\"[FAISS] Created index with {self.total_vectors} vectors of dim {self.dimension}\")\n",
    "        return self\n",
    "    \n",
    "    def create_vectorstore(self, docs, normalize_embeddings=True):\n",
    "        \"\"\"\n",
    "        Create a FAISS vector store from a list of Document objects.\n",
    "        Each document should have metadata like pdf_id, chunk_id, etc.\n",
    "        \n",
    "        Args:\n",
    "            docs: List of Document objects\n",
    "            normalize_embeddings: Whether to normalize embeddings for cosine similarity\n",
    "        \n",
    "        Returns:\n",
    "            self: Returns the FAISS instance for method chaining\n",
    "        \"\"\"\n",
    "        if not self.embedder_model:\n",
    "            raise ValueError(\"Embedder model is required. Set it during initialization or call set_embedder_model()\")\n",
    "        \n",
    "        # Extract texts from Document objects\n",
    "        texts = [doc.page_content for doc in docs]\n",
    "        \n",
    "        # Generate embeddings\n",
    "        embeddings = self.embedder_model.batch_embed(texts)\n",
    "        embeddings = np.array(embeddings).astype(\"float32\")\n",
    "        \n",
    "        # Ensure embeddings are 2D\n",
    "        if embeddings.ndim == 1:\n",
    "            embeddings = embeddings.reshape(1, -1)\n",
    "        \n",
    "        # Initialize FAISS Index\n",
    "        self.dimension = embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatIP(self.dimension)\n",
    "        \n",
    "        # Normalize embeddings for cosine similarity if requested\n",
    "        if normalize_embeddings:\n",
    "            faiss.normalize_L2(embeddings)\n",
    "        \n",
    "        self.index.add(embeddings)\n",
    "        \n",
    "        # Store original Document objects and create mappings\n",
    "        self.documents = docs\n",
    "        self.docstore = {str(i): doc for i, doc in enumerate(docs)}\n",
    "        self.index_to_docstore_id = {i: str(i) for i in range(len(docs))}\n",
    "        \n",
    "        # Also maintain backward compatibility with chunks_dict\n",
    "        self.chunks_dict = {i: doc.page_content for i, doc in enumerate(docs)}\n",
    "        self.total_vectors = self.index.ntotal\n",
    "        \n",
    "        print(f\"[FAISS] Created vectorstore with {self.total_vectors} documents of dim {self.dimension}\")\n",
    "        print(f\"[FAISS] Normalization: {'enabled' if normalize_embeddings else 'disabled'}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def get_relevant_documents(self, query, top_k=5):\n",
    "        \"\"\"Main retriever function - returns LangChain Document objects\"\"\"\n",
    "        if self.index is None:\n",
    "            raise ValueError(\"Index not created. Call create_vector_store() or create_vectorstore() first.\")\n",
    "        \n",
    "        if not self.embedder_model:\n",
    "            raise ValueError(\"Embedder model not set\")\n",
    "        \n",
    "        # Get query embedding\n",
    "        if isinstance(query, str):\n",
    "            # Use embed_query if available, otherwise fall back to batch_embed\n",
    "            if hasattr(self.embedder_model, 'embed_query'):\n",
    "                query_embedding = self.embedder_model.embed_query(query)\n",
    "            else:\n",
    "                query_embedding = self.embedder_model.batch_embed([query])\n",
    "                if isinstance(query_embedding, list) and len(query_embedding) > 0:\n",
    "                    query_embedding = query_embedding[0]\n",
    "                elif isinstance(query_embedding, np.ndarray) and query_embedding.ndim > 1:\n",
    "                    query_embedding = query_embedding[0]\n",
    "        else:\n",
    "            query_embedding = self.embedder_model.batch_embed(query)\n",
    "        \n",
    "        # Search and format results\n",
    "        if self.docstore is not None:\n",
    "            # Use enhanced docstore-based retrieval\n",
    "            results = self._search_with_docstore(query_embedding, top_k)\n",
    "        else:\n",
    "            # Fall back to original chunk-based retrieval\n",
    "            results = self._search_chunks(query_embedding, top_k)\n",
    "            # Convert to Document objects for consistency\n",
    "            results = [\n",
    "                Document(page_content=res['text'], metadata={\"similarity\": res['similarity']})\n",
    "                for res in results\n",
    "            ]\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _search_with_docstore(self, query_embedding, top_k=5):\n",
    "        \"\"\"Enhanced search function using docstore - returns Document objects\"\"\"\n",
    "        # Ensure query_embedding is properly shaped\n",
    "        query_embedding = np.array(query_embedding).astype(\"float32\")\n",
    "        \n",
    "        # Handle different input shapes\n",
    "        if query_embedding.ndim == 1:\n",
    "            query_embedding = query_embedding.reshape(1, -1)\n",
    "        elif query_embedding.ndim > 2:\n",
    "            query_embedding = query_embedding.reshape(1, -1)\n",
    "        \n",
    "        # Verify dimensions match\n",
    "        if query_embedding.shape[1] != self.dimension:\n",
    "            raise ValueError(f\"Query embedding dimension {query_embedding.shape[1]} doesn't match index dimension {self.dimension}\")\n",
    "        \n",
    "        # Search FAISS index\n",
    "        distances, indices = self.index.search(query_embedding, top_k)\n",
    "        \n",
    "        # Format results using docstore\n",
    "        documents = []\n",
    "        for i in range(top_k):\n",
    "            faiss_idx = indices[0][i]\n",
    "            if faiss_idx != -1 and faiss_idx in self.index_to_docstore_id:\n",
    "                docstore_id = self.index_to_docstore_id[faiss_idx]\n",
    "                if docstore_id in self.docstore:\n",
    "                    doc = self.docstore[docstore_id]\n",
    "                    similarity = float(distances[0][i])\n",
    "                    \n",
    "                    # Create a copy of the document with updated metadata\n",
    "                    enhanced_metadata = doc.metadata.copy() if doc.metadata else {}\n",
    "                    enhanced_metadata[\"similarity\"] = similarity\n",
    "                    enhanced_metadata[\"retrieval_index\"] = faiss_idx\n",
    "                    \n",
    "                    enhanced_doc = Document(\n",
    "                        page_content=doc.page_content,\n",
    "                        metadata=enhanced_metadata\n",
    "                    )\n",
    "                    documents.append(enhanced_doc)\n",
    "        \n",
    "        return documents\n",
    "    \n",
    "    def _search_chunks(self, query_embedding, top_k=5):\n",
    "        \"\"\"Internal search function - returns raw results\"\"\"\n",
    "        # Ensure query_embedding is properly shaped\n",
    "        query_embedding = np.array(query_embedding).astype(\"float32\")\n",
    "        \n",
    "        # Handle different input shapes\n",
    "        if query_embedding.ndim == 1:\n",
    "            query_embedding = query_embedding.reshape(1, -1)\n",
    "        elif query_embedding.ndim > 2:\n",
    "            query_embedding = query_embedding.reshape(1, -1)\n",
    "        \n",
    "        print(f\"[DEBUG] Query embedding final shape: {query_embedding.shape}\")\n",
    "        print(f\"[DEBUG] Index dimension: {self.dimension}\")\n",
    "        \n",
    "        # Verify dimensions match\n",
    "        if query_embedding.shape[1] != self.dimension:\n",
    "            raise ValueError(f\"Query embedding dimension {query_embedding.shape[1]} doesn't match index dimension {self.dimension}\")\n",
    "        \n",
    "        # Search FAISS index\n",
    "        distances, indices = self.index.search(query_embedding, top_k)\n",
    "        \n",
    "        # Format results\n",
    "        formatted = []\n",
    "        for i in range(top_k):\n",
    "            faiss_idx = indices[0][i]\n",
    "            if faiss_idx != -1 and faiss_idx < len(self.chunks_dict):\n",
    "                distance = distances[0][i]\n",
    "                formatted.append({\n",
    "                    'chunk_id': faiss_idx,\n",
    "                    'text': self.chunks_dict[faiss_idx],\n",
    "                    'distance': distance,\n",
    "                    'similarity': float(distance)  # For cosine similarity, higher is better\n",
    "                })\n",
    "        \n",
    "        return formatted\n",
    "    \n",
    "    def search_raw(self, query_embedding, top_k=5):\n",
    "        \"\"\"Search with raw embedding input - useful for advanced use cases\"\"\"\n",
    "        return self._search_chunks(query_embedding, top_k)\n",
    "    \n",
    "    def save_index(self, file_path):\n",
    "        \"\"\"Save both FAISS index and metadata\"\"\"\n",
    "        if self.index is None:\n",
    "            raise ValueError(\"No index to save\")\n",
    "        \n",
    "        # Save FAISS index\n",
    "        faiss.write_index(self.index, f\"{file_path}.faiss\")\n",
    "        \n",
    "        # Save metadata (enhanced to include new attributes)\n",
    "        metadata = {\n",
    "            'chunks_dict': self.chunks_dict,\n",
    "            'dimension': self.dimension,\n",
    "            'total_vectors': self.total_vectors,\n",
    "            'index_type': self.index_type,\n",
    "            'docstore': self.docstore,\n",
    "            'index_to_docstore_id': self.index_to_docstore_id,\n",
    "            'documents': self.documents\n",
    "        }\n",
    "        \n",
    "        with open(f\"{file_path}_metadata.pkl\", 'wb') as f:\n",
    "            pickle.dump(metadata, f)\n",
    "        \n",
    "        print(f\"[FAISS] Index and metadata saved to {file_path}\")\n",
    "    \n",
    "    def load_index(self, file_path, embedder_model=None):\n",
    "        \"\"\"Load both FAISS index and metadata\"\"\"\n",
    "        if not os.path.exists(f\"{file_path}.faiss\"):\n",
    "            raise FileNotFoundError(f\"Index file {file_path}.faiss not found\")\n",
    "        \n",
    "        if not os.path.exists(f\"{file_path}_metadata.pkl\"):\n",
    "            raise FileNotFoundError(f\"Metadata file {file_path}_metadata.pkl not found\")\n",
    "        \n",
    "        # Load FAISS index\n",
    "        self.index = faiss.read_index(f\"{file_path}.faiss\")\n",
    "        \n",
    "        # Load metadata\n",
    "        with open(f\"{file_path}_metadata.pkl\", 'rb') as f:\n",
    "            metadata = pickle.load(f)\n",
    "        \n",
    "        self.chunks_dict = metadata['chunks_dict']\n",
    "        self.dimension = metadata['dimension']\n",
    "        self.total_vectors = metadata['total_vectors']\n",
    "        self.index_type = metadata['index_type']\n",
    "        \n",
    "        # Load enhanced attributes if they exist (backward compatibility)\n",
    "        self.docstore = metadata.get('docstore', None)\n",
    "        self.index_to_docstore_id = metadata.get('index_to_docstore_id', None)\n",
    "        self.documents = metadata.get('documents', None)\n",
    "        \n",
    "        # Set embedder model if provided\n",
    "        if embedder_model:\n",
    "            self.embedder_model = embedder_model\n",
    "        \n",
    "        print(f\"[FAISS] Index loaded: {self.total_vectors} vectors, dim {self.dimension}\")\n",
    "        if self.docstore is not None:\n",
    "            print(f\"[FAISS] Enhanced docstore mode enabled\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def set_embedder_model(self, embedder_model):\n",
    "        \"\"\"Set or update the embedder model\"\"\"\n",
    "        self.embedder_model = embedder_model\n",
    "        return self\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get index statistics\"\"\"\n",
    "        return {\n",
    "            'total_vectors': self.total_vectors,\n",
    "            'dimension': self.dimension,\n",
    "            'index_type': self.index_type,\n",
    "            'has_embedder': self.embedder_model is not None,\n",
    "            'has_docstore': self.docstore is not None,\n",
    "            'has_documents': self.documents is not None\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5f5d36",
   "metadata": {},
   "source": [
    "### LLM Abstract Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2c89f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLLM(ABC):\n",
    "    def __init__(self, model_name, cache_folder):\n",
    "        self.model_name = model_name\n",
    "        self.cache_folder = cache_folder\n",
    "        self.device = (\n",
    "            'cuda' if torch.cuda.is_available()\n",
    "            else 'mps' if torch.backends.mps.is_available()\n",
    "            else 'cpu'\n",
    "        )\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_model(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class OLLAMA_LLM(BaseLLM):\n",
    "    def __init__(self, model_name, cache_folder):\n",
    "        super().__init__(model_name, cache_folder)\n",
    "\n",
    "    def load_model(self):\n",
    "        model = Ollama(model=self.model_name, temperature=0.3, num_ctx=4096)\n",
    "        return model\n",
    "\n",
    "\n",
    "class Hugging_Face_LLM(BaseLLM):\n",
    "    def __init__(self, model_name, cache_folder):\n",
    "        super().__init__(model_name, cache_folder)\n",
    "\n",
    "    def load_model(self):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            self.model_name,\n",
    "            cache_dir=self.cache_folder\n",
    "        )\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_name,\n",
    "            cache_dir=self.cache_folder,\n",
    "            torch_dtype=torch.float16 if self.device == \"cuda\" else torch.float32,\n",
    "            device_map=\"auto\"  \n",
    "        )\n",
    "        return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ab7c4d",
   "metadata": {},
   "source": [
    "## Strategy Pattern Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71cb45df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskStrategy(ABC):\n",
    "    \"\"\"Abstract base class defining the strategy interface.\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def run(self, *args, **kwargs):\n",
    "        \"\"\"Execute the strategy. Must be implemented by concrete strategies.\"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5638e6",
   "metadata": {},
   "source": [
    "#### Chatting Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "469a4d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ChattingStrategy(TaskStrategy):\n",
    "    def __init__(self, llm, vector_store, embedder, top_k=5, return_sources=True):\n",
    "        self.llm = llm\n",
    "        self.vector_store = vector_store\n",
    "        self.vector_store.set_embedder_model(embedder)\n",
    "        self.top_k = top_k\n",
    "        self.return_sources = return_sources\n",
    "        self._build_chain()\n",
    "\n",
    "    def format_docs(self, docs):\n",
    "        return \"\\n\\n\".join(\n",
    "            f\"[Source {i} | PDF {doc.metadata.get('pdf_id', '?')}]: {doc.page_content}\"\n",
    "            for i, doc in enumerate(docs, 1)\n",
    "        )\n",
    "\n",
    "    def _build_chain(self):\n",
    "        prompt_template = \"\"\"You are a helpful assistant. Use the following context to answer the question.\n",
    "\n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "            Question: {question}\n",
    "\n",
    "            Please provide a comprehensive answer based on the context above. You MUST follow this exact format:\n",
    "\n",
    "            RESPONSE:\n",
    "            [Your main answer here]\n",
    "\n",
    "            REASONING:\n",
    "            [Explain your reasoning and how you used the context]\n",
    "\n",
    "            SOURCES:\n",
    "            [List the source numbers you referenced, for example: 1, 3, 5]\n",
    "            \"\"\"\n",
    "        \n",
    "        prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "        def retrieve_context(inputs):\n",
    "            docs = self.vector_store.get_relevant_documents(inputs[\"question\"], top_k=self.top_k)\n",
    "            return self.format_docs(docs)\n",
    "\n",
    "        self.chain = ({\n",
    "                \"context\": RunnableLambda(retrieve_context), \n",
    "                \"question\": RunnablePassthrough()\n",
    "            }\n",
    "            | prompt\n",
    "            | self.llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "    def parse_structured_response(self, response_text):\n",
    "        cleaned_response = re.sub(r'<think>.*?</think>', '', response_text, flags=re.DOTALL)\n",
    "        cleaned_response = re.sub(r'<[^>]+>', '', cleaned_response)\n",
    "        cleaned_response = re.sub(r'\\n\\s*\\n', '\\n\\n', cleaned_response.strip())\n",
    "\n",
    "        sections = {'response': '', 'reasoning': '', 'sources': ''}\n",
    "        current_section = None\n",
    "        current_content = []\n",
    "\n",
    "        lines = cleaned_response.split('\\n')\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.upper().startswith('RESPONSE:'):\n",
    "                if current_section:\n",
    "                    sections[current_section] = '\\n'.join(current_content).strip()\n",
    "                current_section = 'response'\n",
    "                current_content = [line[9:].strip()]\n",
    "            elif line.upper().startswith('REASONING:'):\n",
    "                if current_section:\n",
    "                    sections[current_section] = '\\n'.join(current_content).strip()\n",
    "                current_section = 'reasoning'\n",
    "                current_content = [line[10:].strip()]\n",
    "            elif line.upper().startswith('SOURCES:'):\n",
    "                if current_section:\n",
    "                    sections[current_section] = '\\n'.join(current_content).strip()\n",
    "                current_section = 'sources'\n",
    "                current_content = [line[8:].strip()]\n",
    "            elif current_section and line:\n",
    "                current_content.append(line)\n",
    "\n",
    "        if current_section:\n",
    "            sections[current_section] = '\\n'.join(current_content).strip()\n",
    "\n",
    "        source_ids = [int(x) for x in re.findall(r'\\d+', sections['sources'])] if sections['sources'] else []\n",
    "\n",
    "        return {\n",
    "            'answer': sections['response'],\n",
    "            'reasoning': sections['reasoning'],\n",
    "            'sources': source_ids,\n",
    "            'raw_response': cleaned_response\n",
    "        }\n",
    "\n",
    "    def validate_input(self, question):\n",
    "        \"\"\"Validate that the question is a non-empty string.\"\"\"\n",
    "        return isinstance(question, str) and len(question.strip()) > 0\n",
    "\n",
    "    def run(self, question):\n",
    "        \"\"\"Main method to run the chain and parse result.\"\"\"\n",
    "        if not self.validate_input(question):\n",
    "            raise ValueError(\"Question must be a non-empty string\")\n",
    "        \n",
    "        response = self.chain.invoke({\"question\": question})\n",
    "\n",
    "        parsed = self.parse_structured_response(response)\n",
    "        print(f\"Parsed response: {parsed}\")  \n",
    "\n",
    "    \n",
    "        source_docs = self.vector_store.get_relevant_documents(question, top_k=self.top_k)\n",
    "        parsed['source_documents'] = source_docs\n",
    "        parsed['source_texts'] = [doc.page_content for doc in source_docs]\n",
    "        return parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71af65b",
   "metadata": {},
   "source": [
    "#### Summerization Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "769e1c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizationStrategy(TaskStrategy):\n",
    "    def __init__(self, llm, template_file=\"/Users/maryamsaad/Documents/Document_Chatbot/config/prompts/summarization_prompts.yaml\"):\n",
    "        self.llm = llm\n",
    "        self.load_templates(template_file)\n",
    "    \n",
    "    def load_templates(self, template_file):\n",
    "        \"\"\"Load templates from YAML file.\"\"\"\n",
    "        with open(template_file, 'r', encoding='utf-8') as f:\n",
    "            data = yaml.safe_load(f)\n",
    "        self.summary_templates = data.get('summary_templates', {})\n",
    "        self.overview_templates = data.get('overview_templates', {})\n",
    "        \n",
    "    def validate_input(self, document):\n",
    "        \"\"\"Validate that the document is a non-empty string.\"\"\"\n",
    "        return isinstance(document, str) and len(document.strip()) > 0\n",
    "\n",
    "    def run(self, document, length=\"medium\", verbose=False, overview_level=None):\n",
    "        \"\"\"\n",
    "        Summarize the given document with customizable length and optional reasoning,\n",
    "        or create an overview at specified level and length.\n",
    "        \"\"\"\n",
    "        if overview_level:\n",
    "            return self._create_overview(document, overview_level, length, verbose)\n",
    "        return self._create_summary(document, length, verbose)\n",
    "    \n",
    "    def _create_overview(self, document, overview_level, length, verbose=False):\n",
    "        \"\"\"Create an overview of the document at the specified level and length.\"\"\"\n",
    "        template_type = \"with_reasoning\" if verbose else \"base\"\n",
    "        prompt_text = self.overview_templates[overview_level][length][template_type]\n",
    "        \n",
    "        prompt_template = ChatPromptTemplate.from_messages([(\"system\", prompt_text)])\n",
    "        formatted_prompt = prompt_template.format(context=document)\n",
    "        \n",
    "        result = self.llm.invoke(formatted_prompt)\n",
    "  \n",
    "        print(result)\n",
    "        return result\n",
    "    \n",
    "    def _create_summary(self, document, length, verbose):\n",
    "        \"\"\"Create a regular summary of the document.\"\"\"\n",
    "        template_type = \"with_reasoning\" if verbose else \"base\"\n",
    "        prompt_text = self.summary_templates[length][template_type]\n",
    "        \n",
    "        prompt_template = ChatPromptTemplate.from_messages([(\"system\", prompt_text)])\n",
    "        formatted_prompt = prompt_template.format(context=document)\n",
    "        \n",
    "        result = self.llm.invoke(formatted_prompt)\n",
    "   \n",
    "        print(result)\n",
    "        return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab426167",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Summarization_Rag_Strategy(TaskStrategy):\n",
    "    def __init__(self, llm,retriever):\n",
    "        self.llm = llm\n",
    "        self.retriever=retriever\n",
    "        self.prompt = PromptTemplate(\n",
    "            input_variables=[\"user_prompt\", \"context\"],\n",
    "            template=\"\"\"\n",
    "            You are a helpful assistant.\n",
    "\n",
    "            The user is interested in the topic: \"{user_prompt}\"\n",
    "\n",
    "            Based on the following document excerpts, generate a structured summary.\n",
    "\n",
    "            Only use the provided content—do not include prior knowledge or assumptions.\n",
    "\n",
    "            == Document Excerpts ==\n",
    "            {context}\n",
    "\n",
    "            == Summary ==\n",
    "            **Main Topic:** [Summarize the general theme of the retrieved content.]\n",
    "\n",
    "            **Key Points:**\n",
    "            - [Most relevant insight #1]\n",
    "            - [Relevant insight #2]\n",
    "            - [Relevant insight #3]\n",
    "\n",
    "            **Supporting Details:** [Specific numbers, quotes, or facts.]\n",
    "\n",
    "            **Conclusion:** [Key implication or recommendation.]\n",
    "            \"\"\"\n",
    "        )\n",
    "                \n",
    "\n",
    "    def validate_input(self, documents):\n",
    "        \"\"\"Validate that the input is a non-empty list of Document objects.\"\"\"\n",
    "        return isinstance(documents, list) and all(isinstance(doc, Document) for doc in documents)\n",
    "\n",
    "    def run(self, prompt):\n",
    "        \"\"\"Retrieve and summarize relevant chunks.\"\"\"\n",
    "        similar_chunks = self.retriever.get_relevant_documents(prompt)\n",
    "\n",
    "        positively_correlated = [\n",
    "            chunk for chunk in similar_chunks\n",
    "            if chunk.metadata.get('similarity', 0) > 0.1\n",
    "        ]\n",
    "\n",
    "        if not positively_correlated:\n",
    "            raise ValueError(\"No chunks above similarity threshold.\")\n",
    "\n",
    "        combined_text = \"\\n\\n\".join([\n",
    "            f\"[Chunk from page {doc.metadata.get('page', 'N/A')}]:\\n{doc.page_content}\" \n",
    "            for doc in positively_correlated\n",
    "        ])\n",
    "\n",
    "\n",
    "        formatted_prompt = self.prompt.format(user_prompt=prompt, context=combined_text)\n",
    "        result = self.llm.invoke(formatted_prompt)\n",
    "\n",
    "        print(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deff017",
   "metadata": {},
   "source": [
    "#### Question Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0bade4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionStrategy(TaskStrategy):\n",
    "    def __init__(self, llm, complexity=\"medium\"):\n",
    "        self.llm = llm\n",
    "        self.complexity = complexity\n",
    "        self._set_prompt()\n",
    "    \n",
    "    def _set_prompt(self):\n",
    "        complexity_instructions = {\n",
    "            \"easy\": \"Generate simple, basic questions that test understanding of key facts and definitions.\",\n",
    "            \"medium\": \"Generate moderately challenging questions that require analysis and understanding of concepts.\",\n",
    "            \"hard\": \"Generate complex questions that require critical thinking, analysis, and synthesis of information.\"\n",
    "        }\n",
    "        \n",
    "        instruction = complexity_instructions.get(self.complexity, complexity_instructions[\"medium\"])\n",
    "        \n",
    "        self.prompt = ChatPromptTemplate.from_template(f\"\"\"\n",
    "        You are a helpful assistant tasked with generating question-answer pairs for study purposes.\n",
    "\n",
    "        Text:\n",
    "        {{context}}\n",
    "\n",
    "        {instruction}\n",
    "        Generate {{Questions}} meaningful questions based only on the above text. \n",
    "\n",
    "        IMPORTANT: Format your output exactly as shown below with no additional text, explanations, or formatting:\n",
    "\n",
    "        Q1: [question text]\n",
    "        Q2: [question text]\n",
    "        Q3: [question text]\n",
    "        \"\"\")\n",
    "        self.qa_chain = self.prompt | self.llm | StrOutputParser()\n",
    "\n",
    "\n",
    "    def set_complexity(self, complexity):\n",
    "        \"\"\"Change complexity level with synonym mapping and fuzzy matching.\"\"\"\n",
    "        import difflib\n",
    "        \n",
    "        complexity = complexity.lower().strip()\n",
    "        \n",
    "        # Handle synonyms first\n",
    "        synonyms = {\n",
    "            \"challenging\": \"hard\", \"difficult\": \"hard\", \"tough\": \"hard\",\n",
    "            \"simple\": \"easy\", \"basic\": \"easy\", \"beginner\": \"easy\", \n",
    "            \"moderate\": \"medium\", \"average\": \"medium\", \"normal\": \"medium\"\n",
    "        }\n",
    "        \n",
    "        if complexity in synonyms:\n",
    "            self.complexity = synonyms[complexity]\n",
    "            self._set_prompt()\n",
    "            return\n",
    "        \n",
    "        # Check exact match\n",
    "        valid_options = [\"easy\", \"medium\", \"hard\"]\n",
    "        if complexity in valid_options:\n",
    "            self.complexity = complexity\n",
    "            self._set_prompt()\n",
    "            return\n",
    "        \n",
    "        # Fuzzy matching against synonyms first\n",
    "        all_options = list(synonyms.keys()) + valid_options\n",
    "        matches = difflib.get_close_matches(complexity, all_options, n=1, cutoff=0.6)\n",
    "        \n",
    "        if matches:\n",
    "            best_match = matches[0]\n",
    "            similarity = difflib.SequenceMatcher(None, complexity, best_match).ratio()\n",
    "            print(f\"'{complexity}' matched to '{best_match}' ({similarity:.0%} confidence)\")\n",
    "            \n",
    "            # Map to final complexity\n",
    "            final_complexity = synonyms.get(best_match, best_match)\n",
    "            self.complexity = final_complexity\n",
    "            self._set_prompt()\n",
    "        else:\n",
    "            raise ValueError(\"Please use: 'easy', 'medium', 'hard', or synonyms like 'challenging', 'simple'\")\n",
    "\n",
    "\n",
    "\n",
    "    def parse_qa_pairs(self, qa_output):\n",
    "        qa_pairs = []\n",
    "        lines = qa_output.strip().split('\\n')\n",
    "        i = 0\n",
    "        while i < len(lines):\n",
    "            q_match = re.match(r'Q(\\d+):\\s*(.+)', lines[i])\n",
    "            if q_match and i + 1 < len(lines):\n",
    "                question = q_match.group(2).strip()\n",
    "                a_match = re.match(f'A{q_match.group(1)}:\\s*(.+)', lines[i + 1])\n",
    "                if a_match:\n",
    "                    answer = a_match.group(1).strip()\n",
    "                    qa_pairs.append({'question': question, 'answer': answer})\n",
    "                    i += 2\n",
    "                else:\n",
    "                    i += 1\n",
    "            else:\n",
    "                i += 1\n",
    "        return qa_pairs\n",
    "\n",
    "    def validate_input(self, doc):\n",
    "        \"\"\"Validate that the document is a Document instance with content.\"\"\"\n",
    "        return (isinstance(doc, Document) and \n",
    "                hasattr(doc, 'page_content') and \n",
    "                len(doc.page_content.strip()) > 0)\n",
    "    \n",
    "    def run(self, doc, questions, complexity='simple'):\n",
    "        \"\"\"Generate questions from the given document.\"\"\"\n",
    "        if not self.validate_input(doc):\n",
    "            raise ValueError(\"Input must be a Document with non-empty page_content\")\n",
    "        \n",
    "        # Update complexity if provided\n",
    "        if complexity is not None:\n",
    "            self.set_complexity(complexity)\n",
    "            \n",
    "        try:\n",
    "            qa_output = self.qa_chain.invoke({\"context\": doc.page_content,\"Questions\":questions})\n",
    "            parsed_qa = self.parse_qa_pairs(qa_output)\n",
    "            print(qa_output)\n",
    "            print(parsed_qa)\n",
    "\n",
    "            return {\n",
    "                \"pdf_id\": doc.metadata.get(\"pdf_id\"),\n",
    "                \"chunk_id\": doc.metadata.get(\"chunk_id\"),\n",
    "                \"text\": doc.page_content,\n",
    "                \"qa_output\": qa_output,\n",
    "                \"parsed_qa\": parsed_qa\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ QA generation failed for Document {doc.metadata}: {e}\")\n",
    "            return None\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71a15e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskProcessor:\n",
    "    \"\"\"Context class that uses different task strategies.\"\"\"\n",
    "    \n",
    "    def __init__(self, strategy=None):  \n",
    "        self._strategy = strategy      \n",
    "    \n",
    "    @property\n",
    "    def strategy(self):\n",
    "        return self._strategy\n",
    "         \n",
    "    @strategy.setter\n",
    "    def strategy(self, strategy):\n",
    "        self._strategy = strategy\n",
    "         \n",
    "    def execute_task(self, *args, **kwargs):\n",
    "        if self._strategy is None:      # ✅ Add this check\n",
    "            raise ValueError(\"No strategy set\")\n",
    "        return self._strategy.run(*args, **kwargs)\n",
    "         \n",
    "    def switch_strategy(self, new_strategy):\n",
    "        self.strategy = new_strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a47f073",
   "metadata": {},
   "source": [
    "## Classes Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "785f0200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total Chunks: 11\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Testing cell\n",
    "paths=['/Users/maryamsaad/Documents/Graduation_Proj/junk/chapter4_GT.json']\n",
    "docs=JSONPreprocessor()\n",
    "data=docs.process_documents_from_files(paths)\n",
    "individual_documents = [ Document(page_content=pdf.page_content, metadata={\"pdf_id\": i})\n",
    "    for i, pdf in enumerate(data) if pdf.page_content\n",
    "]\n",
    "chunked_docs=docs.chunk_documents(individual_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c14c74f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken to process:   6.443945407867432\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "multilingual_embedder=MultilingualEmbedder(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", batch_size=32)\n",
    "end=time.time()\n",
    "print(\"Time Taken to process:  \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5194a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken to process:   0.0012359619140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c2/f9lh6rmd4q1648_pfl1636zw0000gn/T/ipykernel_86244/3805475503.py:21: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  model = Ollama(model=self.model_name, temperature=0.3, num_ctx=4096)\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "llm=OLLAMA_LLM('llama3:8b','llm_cache').load_model()\n",
    "end=time.time()\n",
    "print(\"Time Taken to process:  \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6187b37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start=time.time()\n",
    "# basic_fais=FAISSBasic(multilingual_embedder)\n",
    "# basic_fais.create_vector_store(chunked_docs)\n",
    "# end=time.time()\n",
    "# print(\"Time Taken to process:  \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "431ed67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FAISS] Created index with 11 vectors of dim 384\n",
      "Time Taken to process:   20.425259113311768\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "fais_improved = FAISSImproved()\n",
    "fais_improved.set_embedder_model(multilingual_embedder)\n",
    "fais_improved.create_vector_store(chunked_docs)\n",
    "end=time.time()\n",
    "print(\"Time Taken to process:  \", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c3cb1e",
   "metadata": {},
   "source": [
    "#### Strategy implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d297857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken to process:   0.012579917907714844\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "chatting_strategy = ChattingStrategy(llm, fais_improved, multilingual_embedder)\n",
    "summarization_strategy = SummarizationStrategy(llm)\n",
    "question_strategy = QuestionStrategy(llm)\n",
    "rag_summary=Summarization_Rag_Strategy(llm,fais_improved)\n",
    "processor = TaskProcessor()\n",
    "end=time.time()\n",
    "print(\"Time Taken to process:  \", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c359c7",
   "metadata": {},
   "source": [
    "##### Arabic test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d3b307c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Query embedding final shape: (1, 384)\n",
      "[DEBUG] Index dimension: 384\n",
      "Parsed response: {'answer': 'The subject of this file is psychological and social harmony, coping mechanisms, and defense strategies.', 'reasoning': 'Based on the provided context, it appears that the main topic is related to psychology and sociology. The text mentions concepts such as \"توافق\" (harmony), \"إحباط\" (frustration), \"صراع\" (conflict), and various coping mechanisms like \"الإعلان\" (assertion), \"التعويض\" (compensation), \"الإسقاط\" (denial), \" التقصص\" (identification), and \"التكوص\" (regression). The context also touches upon the importance of social harmony, emotional regulation, and defense strategies.', 'sources': [1, 2, 3, 4], 'raw_response': 'RESPONSE:\\nThe subject of this file is psychological and social harmony, coping mechanisms, and defense strategies.\\n\\nREASONING:\\nBased on the provided context, it appears that the main topic is related to psychology and sociology. The text mentions concepts such as \"توافق\" (harmony), \"إحباط\" (frustration), \"صراع\" (conflict), and various coping mechanisms like \"الإعلان\" (assertion), \"التعويض\" (compensation), \"الإسقاط\" (denial), \" التقصص\" (identification), and \"التكوص\" (regression). The context also touches upon the importance of social harmony, emotional regulation, and defense strategies.\\n\\nSOURCES:\\n1, 2, 3, 4'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process SpawnProcess-11:\n",
      "Process SpawnProcess-10:\n",
      "Process SpawnProcess-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 116, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/spawn.py\", line 126, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/Users/maryamsaad/Library/Python/3.9/lib/python/site-packages/sentence_transformers/__init__.py\", line 10, in <module>\n",
      "    from sentence_transformers.backend import (\n",
      "  File \"/Users/maryamsaad/Library/Python/3.9/lib/python/site-packages/sentence_transformers/backend.py\", line 11, in <module>\n",
      "    from sentence_transformers.util import disable_datasets_caching, is_datasets_available\n",
      "  File \"/Users/maryamsaad/Library/Python/3.9/lib/python/site-packages/sentence_transformers/util.py\", line 27, in <module>\n",
      "    from transformers import is_torch_npu_available\n",
      "  File \"/Users/maryamsaad/Library/Python/3.9/lib/python/site-packages/transformers/__init__.py\", line 1015, in <module>\n",
      "    import_structure = define_import_structure(Path(__file__).parent / \"models\", prefix=\"models\")\n",
      "  File \"/Users/maryamsaad/Library/Python/3.9/lib/python/site-packages/transformers/utils/import_utils.py\", line 2428, in define_import_structure\n",
      "    import_structure = create_import_structure_from_path(module_path)\n",
      "  File \"/Users/maryamsaad/Library/Python/3.9/lib/python/site-packages/transformers/utils/import_utils.py\", line 2171, in create_import_structure_from_path\n",
      "    import_structure[f] = create_import_structure_from_path(os.path.join(module_path, f))\n",
      "  File \"/Users/maryamsaad/Library/Python/3.9/lib/python/site-packages/transformers/utils/import_utils.py\", line 2195, in create_import_structure_from_path\n",
      "    with open(os.path.join(directory, module_name), encoding=\"utf-8\") as f:\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/codecs.py\", line 309, in __init__\n",
      "    def __init__(self, errors='strict'):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/maryamsaad/Library/Python/3.9/lib/python/site-packages/sentence_transformers/SentenceTransformer.py\", line 1501, in _encode_multi_process_worker\n",
      "    chunk_id, inputs, kwargs = input_queue.get()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/maryamsaad/Library/Python/3.9/lib/python/site-packages/sentence_transformers/SentenceTransformer.py\", line 1501, in _encode_multi_process_worker\n",
      "    chunk_id, inputs, kwargs = input_queue.get()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/maryamsaad/Library/Python/3.9/lib/python/site-packages/sentence_transformers/SentenceTransformer.py\", line 1501, in _encode_multi_process_worker\n",
      "    chunk_id, inputs, kwargs = input_queue.get()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/connection.py\", line 221, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/connection.py\", line 419, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/connection.py\", line 384, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m processor\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m=\u001b[39mchatting_strategy\n\u001b[0;32m----> 2\u001b[0m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mما موضوع هذا الملف\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 18\u001b[0m, in \u001b[0;36mTaskProcessor.execute_task\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:      \u001b[38;5;66;03m# ✅ Add this check\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo strategy set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 108\u001b[0m, in \u001b[0;36mChattingStrategy.run\u001b[0;34m(self, question)\u001b[0m\n\u001b[1;32m    104\u001b[0m parsed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_structured_response(response)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParsed response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparsed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \n\u001b[0;32m--> 108\u001b[0m source_docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvector_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtop_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m parsed[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_documents\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m source_docs\n\u001b[1;32m    110\u001b[0m parsed[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_texts\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m source_docs]\n",
      "Cell \u001b[0;32mIn[7], line 105\u001b[0m, in \u001b[0;36mFAISSImproved.get_relevant_documents\u001b[0;34m(self, query, top_k)\u001b[0m\n\u001b[1;32m    103\u001b[0m     query_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedder_model\u001b[38;5;241m.\u001b[39membed_query(query)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 105\u001b[0m     query_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedder_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(query_embedding, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(query_embedding) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    107\u001b[0m         query_embedding \u001b[38;5;241m=\u001b[39m query_embedding[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[4], line 36\u001b[0m, in \u001b[0;36mMultilingualEmbedder.batch_embed\u001b[0;34m(self, texts, batch_size)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(texts), batch_size):\n\u001b[1;32m     35\u001b[0m     batch \u001b[38;5;241m=\u001b[39m texts[i:i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[0;32m---> 36\u001b[0m     batch_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     embeddings\u001b[38;5;241m.\u001b[39mextend(batch_embeddings)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(embeddings, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_huggingface/embeddings/huggingface.py:150\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21membed_documents\u001b[39m(\u001b[38;5;28mself\u001b[39m, texts: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[1;32m    142\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute doc embeddings using a HuggingFace transformer model.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m        List of embeddings, one for each text.\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langchain_huggingface/embeddings/huggingface.py:123\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings._embed\u001b[0;34m(self, texts, encode_kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m texts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m), texts))\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmulti_process:\n\u001b[0;32m--> 123\u001b[0m     pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_multi_process_pool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mencode_multi_process(texts, pool)\n\u001b[1;32m    125\u001b[0m     sentence_transformers\u001b[38;5;241m.\u001b[39mSentenceTransformer\u001b[38;5;241m.\u001b[39mstop_multi_process_pool(pool)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sentence_transformers/SentenceTransformer.py:1306\u001b[0m, in \u001b[0;36mSentenceTransformer.start_multi_process_pool\u001b[0;34m(self, target_devices)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m device_id \u001b[38;5;129;01min\u001b[39;00m target_devices:\n\u001b[1;32m   1301\u001b[0m     p \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mProcess(\n\u001b[1;32m   1302\u001b[0m         target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_multi_process_worker,\n\u001b[1;32m   1303\u001b[0m         args\u001b[38;5;241m=\u001b[39m(device_id, \u001b[38;5;28mself\u001b[39m, input_queue, output_queue),\n\u001b[1;32m   1304\u001b[0m         daemon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   1305\u001b[0m     )\n\u001b[0;32m-> 1306\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m     processes\u001b[38;5;241m.\u001b[39mappend(p)\n\u001b[1;32m   1309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m: input_queue, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_queue, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprocesses\u001b[39m\u001b[38;5;124m\"\u001b[39m: processes}\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[1;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    120\u001b[0m _cleanup()\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/context.py:284\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_posix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[0;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_spawn_posix.py:32\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_fork.py:19\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinalizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/multiprocessing/popen_spawn_posix.py:62\u001b[0m, in \u001b[0;36mPopen._launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentinel \u001b[38;5;241m=\u001b[39m parent_r\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m, closefd\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 62\u001b[0m         \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m     fds_to_close \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n"
     ]
    }
   ],
   "source": [
    "processor.strategy=chatting_strategy\n",
    "processor.execute_task(\"ما موضوع هذا الملف\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3abd399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a brief low-level overview of the document:\n",
      "\n",
      "**Key Details:**\n",
      "\n",
      "* The most critical technical detail is the discussion on conflict resolution strategies, including direct and indirect methods.\n",
      "* The most important data point is the various ways people cope with stress and conflict.\n",
      "\n",
      "**Action Items:**\n",
      "\n",
      "* Understand the different approaches to conflict resolution, including direct and indirect methods.\n",
      "* Recognize the importance of coping mechanisms in dealing with stress and conflict.\n",
      "\n",
      "The document discusses various aspects of personality, conflict, and coping mechanisms. It covers topics such as:\n",
      "\n",
      "* Conflict resolution strategies (direct and indirect)\n",
      "* Coping mechanisms (e.g., suppression, denial, rationalization)\n",
      "* Personality theories (e.g., Freudian, behavioral)\n",
      "* The role of social factors in shaping behavior\n",
      "* The importance of understanding human emotions and behaviors\n",
      "\n",
      "The document is written in a formal and academic tone, with a focus on providing an overview of the concepts and theories discussed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Here is a brief low-level overview of the document:\\n\\n**Key Details:**\\n\\n* The most critical technical detail is the discussion on conflict resolution strategies, including direct and indirect methods.\\n* The most important data point is the various ways people cope with stress and conflict.\\n\\n**Action Items:**\\n\\n* Understand the different approaches to conflict resolution, including direct and indirect methods.\\n* Recognize the importance of coping mechanisms in dealing with stress and conflict.\\n\\nThe document discusses various aspects of personality, conflict, and coping mechanisms. It covers topics such as:\\n\\n* Conflict resolution strategies (direct and indirect)\\n* Coping mechanisms (e.g., suppression, denial, rationalization)\\n* Personality theories (e.g., Freudian, behavioral)\\n* The role of social factors in shaping behavior\\n* The importance of understanding human emotions and behaviors\\n\\nThe document is written in a formal and academic tone, with a focus on providing an overview of the concepts and theories discussed.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.strategy=summarization_strategy \n",
    "processor.execute_task(individual_documents[0].page_content,length=\"short\",verbose=True,overview_level='low_level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4480414c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Query embedding final shape: (1, 384)\n",
      "[DEBUG] Index dimension: 384\n",
      "**Main Topic:** Rights and Conflict Resolution Strategies\n",
      "\n",
      "**Key Points:**\n",
      "\n",
      "* The importance of recognizing the difference between frustration and conflict\n",
      "* The need to identify and address underlying causes of frustration and conflict\n",
      "* The use of various strategies for resolving conflicts, including:\n",
      "\t+ Direct methods (e.g., replacing a goal with another one, using problem-solving skills)\n",
      "\t+ Indirect methods (e.g., suppression, denial, projection)\n",
      "\n",
      "**Supporting Details:**\n",
      "\n",
      "* Examples of direct methods include:\n",
      "\t+ Replacing a goal with another one\n",
      "\t+ Using problem-solving skills to overcome obstacles\n",
      "\t+ Seeking alternative solutions\n",
      "* Examples of indirect methods include:\n",
      "\t+ Suppression: repressing or hiding one's emotions or desires\n",
      "\t+ Denial: refusing to acknowledge the existence of a problem or conflict\n",
      "\t+ Projection: attributing one's own thoughts, feelings, or motivations to someone else\n",
      "\n",
      "**Conclusion:** Effective conflict resolution requires a combination of direct and indirect strategies. By recognizing the underlying causes of frustration and conflict, individuals can develop more effective coping mechanisms and work towards resolving conflicts in a constructive manner.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"**Main Topic:** Rights and Conflict Resolution Strategies\\n\\n**Key Points:**\\n\\n* The importance of recognizing the difference between frustration and conflict\\n* The need to identify and address underlying causes of frustration and conflict\\n* The use of various strategies for resolving conflicts, including:\\n\\t+ Direct methods (e.g., replacing a goal with another one, using problem-solving skills)\\n\\t+ Indirect methods (e.g., suppression, denial, projection)\\n\\n**Supporting Details:**\\n\\n* Examples of direct methods include:\\n\\t+ Replacing a goal with another one\\n\\t+ Using problem-solving skills to overcome obstacles\\n\\t+ Seeking alternative solutions\\n* Examples of indirect methods include:\\n\\t+ Suppression: repressing or hiding one's emotions or desires\\n\\t+ Denial: refusing to acknowledge the existence of a problem or conflict\\n\\t+ Projection: attributing one's own thoughts, feelings, or motivations to someone else\\n\\n**Conclusion:** Effective conflict resolution requires a combination of direct and indirect strategies. By recognizing the underlying causes of frustration and conflict, individuals can develop more effective coping mechanisms and work towards resolving conflicts in a constructive manner.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.strategy=rag_summary\n",
    "processor.execute_task(\"حقوق\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f71d7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: What are the direct methods to overcome conflicts and frustrations?\n",
      "\n",
      "Q2: What is the concept of \"replacement\" in psychology?\n",
      "\n",
      "Q3: What is the difference between psychological and social compatibility?\n",
      "\n",
      "Q4: What is the definition of frustration according to the text?\n",
      "\n",
      "Q5: What are some examples of defensive mechanisms mentioned in the text?\n",
      "\n",
      "Q6: What is the purpose of studying personality types?\n",
      "\n",
      "Q7: Can a person's personality be determined by their physical characteristics? Why or why not?\n",
      "\n",
      "Q8: What is the difference between psychological and social compatibility?\n",
      "\n",
      "Q9: What are some consequences of frustration and conflict?\n",
      "\n",
      "Q10: What are some examples of direct methods to overcome conflicts and frustrations mentioned in the text?\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pdf_id': 0,\n",
       " 'chunk_id': None,\n",
       " 'text': 'الفصل الرابعأساليب حل الصراعات ومواجهة الاحتياطات-اولًا: الأساليب المباشرةيستطيع معظم الناس التغلب على مواقف الإحباط والصراع وما ينشأ عنها من عدم توافق باللجوء إلى الأساليب المباشرة ، والتي تستخدم في حل مشكلات التوافق حلا حاسماً وبنهائياً، وأهم هذه الطرق ما يأتي: أ- بدل الجهد لإزالة العائق والوصول إلى الهدف : إن أول طريق مباشرة للتغلب على مواقف الإحباط والصراع، وما يتضمنه من عوائق تحول دون إشباع الدواقع أو الوصول إلى الأهداف هي القيام بعمل جديّ، ومضاوعة الجهد لإزالة هذه العوائق، فالطالب الذي يرسبِّ فَى الإمتحان يحاول أن يزيد من مجهوده فى استتذكار دروسه حتى ينجح فى الامتحان عند إعادته ويتفوق فيه .– البحث عن طرق أخرى للوصول الى الهدف : إذا وجد الشخص أن الطريقة التي يستخدمها للوصول إلى الهدف لا تؤدى لى ذلك بالرغم مما يبدوُله من جهد ونشاط؛ فإنه بيبدأ في البحث عن طريقة أخرى تؤدى لى ذلك ، فالطالب فى المثال السابق قد يلجاْ إلى تغيير عاداته فى الاستتذكار ، وهذه الطريقة لا تصلح إلا إذ كان العائق خارجياً أو كان ناجماً عن عوبش شخصية يمكن تقادييها وعلاجها .– استبدال الهدف بغيره :إذا فمثل الشخص فى التنقل على الإحباط والصراع والوصول الى الهدف بإحدى الطريقتين السابقتين فإنھ حينئذ يلجاْ لى الطريقة ثلثاه وهي تغيب الهدف نفسه ، وإجمال هدف آخر يسهل الوصول إليه محله ، وتتوقف كفاءة هذا الطريقة على نجاح الهدف الجديد عند إحرازه بالإشباع الدافع لى الحاجة ، لتفرض أنك كنت تتنيآ للعب كرة قدم ؛ فأمطرت السماء واضطررت الى النبقاء فى المنزل ، واخذت تشاهد التليفزيون ، فإذا كان هذلك من لعبة كرة القدم مرتبطاً برغبتك فى التسلية وقضاء وقت الفرغ؟ فإن الهدف البديل () وهو مشاهدة التليفزيون) يمكنك أن يشبع هذه الحاجة ، أما إذا كان لعب كرة القدم هدفاً لل حاجة إلى التقدير فإن مشاهدة التليفزيون لن تكون هدفا بديلا.*استخدام أسلوب حل المشكلة :يمكن للشخص الذي يعاني من خبرة الإحباط او الصراع ان يلجأ إلى طرخ مباشرة للوصول لى الهدف وتحقيق التوافق وهى أسلبٍ حل المشكلبة، وتتطلب هذه الطريقة أن يحاول الشخص جميع أكبر.\\nقدر من المعلومات عن الهدف الذي يسعى إليه ، أو الأهداف المتضارعة لديه ، ثم يجرب عمليات التحليل المعتادة في سلوك حل المشكلة ، ويجري الوصول إلى الهدف ليتعرف على عواقبه وتتابعبه ، وقد ينبغي به ذلك إلى قبول الهدف أو التخلى عنه ، وفي حالة الصراع قد يتخلّى عن أحد الهدفين او عنهما معاً وقد يحاول التوفيق بينهما.ثانيا: الأساليب غير المباشرةإذا فثلتت الأساليب المباشرة فى التغلب على الإحباط أو الصراع فإن حالة التوتر النفسي الناشئة عنها ما تستمر لفترة طويلة على نحو يسبب للشخص كثيرا من القلق والألم والضيق ، وذلك يتلمس الشخص بعض الطريق غير المباشرة لتخفيف حدة التوتر الناجم عن الإحباط والصراع ، وهذه الأمالييب غير المباشرة تتسم بأنها لا شوعورية ، وبعضها قد يكون أقرب الى السواء ، ويمارسها معظم الناس وتسمنى الحيل الدفاعية ومنها:--..(١) الكبت : الكبت هو نوع من التنسان اللاشعوري يسعى المرء ، بطريقة لا إرادية إلى إبعاد الدوافع غير المقولة والتكريريات المؤملة أو المشينة أو الخبيفة دون دائرة الشعور والوعي ، وإخفائها في الللاشعور، والتي تظهر فيما بعد في شكَل أحلام اليوم، الهفروات ولذات اللسان.مثال: استبعد الطفل لمشاعر العدوانية تجاه أبيه عندما يغنه بشده(٢)الإعلان ( التسليم) )الإعلان أو التسليم هو تحويل الطاقة النفسية المتعلقة بأحد الدوافع أو الأهداف غير المقولة اجتماعيا وتوجيهها إلى نشاط اجتماعي مقول ومفيد ، فالدافع الجنسي مثلًا يمكن علاقته بالنشاط الأدبِي والفني والرغبات العدوانية يمكن أن تتسامى من خلال بعض الأنطمة الرياضية .مثال: ممارسة رياضة الملاكمة والكارازاته هي إعلاء للغزيزة العدوانية في شكَل مقبول اجتماعي.(٣): التعويض :التعويض هو حيلة دفاعية لاشعرورية يلجأ إليها الفرد لتخفيف حدّة التوتر الناجم عن صراع وما بصاحبها من شعار بالنقص أو إحساس بالفشل ، وهو نوع من تنغيير الأهداف إلا أنه فى حالة التعويض يكون لاشعروريا.مثال: فضل الفرد في مجال معين يعوضه في مجال آخر ؟(٤)التبشير هو محاولة لاشعرورية لإعطاء أسباب تبدو مقبولة اجتماعية، أو معقولة منطقةا على الرغم من أنها بالفعل غير سليمة.\\nمثال: الطالب الذي يبرر عدم إنجازه لواجباته بالمرض.(٩) الإزاحة ( ) الإحلال أو النقل () : ه)الإزالة حيلة دفاعية بلجاً إليها الشخص لنقل الانفعالات من معانيها الأصلية غير المقبولة إلى ماعن آخرى بديلة تكون أكثر قبولاً لدى الشخص ، وقد تتخذ الإدارة صورة النقل من أشياء أو أشخاص معينين إلى أشخاص أخرين .مثال: الموظف الذي يغضببه رئيسه قد بنقل غضبيه إلى زوجته أو أبنائه .(٢) الإسقاط :الإسفاقط حيلة أخرى بلجاً إليها الإنسان حين يلصق عيوبيه أو نقاصنه أو فتله بالأخرین ، وهو بذلك وسيلة إنكار وجود هذه العيبو أو الأخطة فيه ، ومن الإسقاط أيضاً أن ينسب المرء الى شخص آخر مستولية الأفععال التي يوجد أن بييراً منها .مثال: الشخص الذي يشعر بالكراهبة نحو شخص آخر قد يسقط ذلك عليه، ويذركه على أنه يضمر له العداء .(٧) التقصص (التوحد) : حيلة التنقص هي عكس حيلة الإسقاط ، وفيها يستعى المرء الى خفض التوتر النفسي الناجم عن الإحباط والصراع عن طريق التحلى ببعض الصفقات والحخصائص التي يتسم بها شخص آخر ، أو عن طريق التوحد الوجداني مع هذا الشخص، ومن ذلك توجد الطفل الصغير مع والده أو الطالب مع أستاذه .(٨) التكوص:التكوص هو ارتداد إلى بعض أساليب التواصل القديمة التي كانت تشيع رغبات الشخص وتحقق أهدافه في مرحلة سابقة من مراكز نموه ، على الرغم من أنه يكون قد تعدى هذه المرحلة .مثال: عودة الطفل إلى الثبول اللاراديحين يلاحظ انصرفاه اهماموالديه إلى شقيقه المؤولد حديثًا ، ويعتير التكوص فى هذه الحالة حيلة لاشعورية لجنبان انتقاء الوالدين إليه(٩) الإنكار : تظاهر هذه الحياة فى صورة رفض الشخص الاعتراف بأنه فى حالة إحباط أو صراع .مثال: شعور الناجر بالإرضاء على الرغم من أن تجارته تتنهار وكاد يفسد[١٠]\\nالأسللة الתקويمية - عرف الشخصية كمثير .٢- اذكر الملاحظات التي وجهت لتعريف الشخصية كمثير .- عرف مفهوم الشخصية كاستجابة ؟– استخلص الملاحظات التي وجهت إلى تعريف الشخصية كاستجابة ه– ميز بين كل من تعريف الشخصية كمثير وتعرف الشخصية كاستجابة.- ؟– استخلص المحددات التي قامت عليها نظرية التحليل النفسي .٧– وضع دور المتغيرات الاجتماعية والتفاعل الاجتماعي وفقا للاتجاهات الحديثة لنظرية التحليل النفسي .٨– أعرض النظرية السلوكية في الشخصية.- ?– عرف الشخصية من وجهة نظر ألبرزت.*ـ ١– استخلص ما يضمنه تعرف ألبرزت للشخصية من أفكار أو عناصر .**ـ ٠– اعرض لأنماط الشخصية في ضوء ما درست،*ـ ٣– ميز بين أنماط الشخصية في ضوء ما درست ،*ـ ٤– استخلص الانتقادات التي وجهت لنظرية الأنماط.*ـ ٥– هل تعتبر بإمكانية الحكم على شخصية ما من خلال أنماط أومكونات الجسم ؛، انكر مبرراتك*ـ ٦– نشأ المنحى الإنساني كرد فعل لووجهة نظر كل من التحليل النفسى والسلوكية.هل تويد ذلك ولمذا؟..*ـ ٩– قام المنحى الإنسانى علي عدد من الاقتراضاوات، حددها.*ـ ٢– عدد النماذج المختلفة لبعض أنواع الشخصيات.*ـ ٤– أعط مثلًا لكل نموذج من النماذج المختلفة للشخصية.*ـ ٩– تتعدد نماذج الشخصيات المختلفة بناءً علي التنظريات التي قامت في ضوئها\". مع أي النماذج تميل ؟ولماذا؟.\".*ـ ٢– في ضوء فهمك للتعرف العلمي للشخصية .هل ترى ضرورة لهذه الأنواع المختلفة من الشخصية؟ علل لوجهة نظرك.*ـ ٢– عرف الإتجاه.*ـ ٢ٔ– لدراسة الاتجاهات أهمية، اعرض في ضوء ما درست.*ـ ٢ٓ– يرجع انتشار مفهوم الإتجاه وكثرة استخدامه إلى عدة أسباب، ناقش.\\n٢١– عرض بإيجاز أسباب انتشار مفهوم الاتجاه وكثرة استخدامه، . تعدد خصائص الاتجاهات.اعرض في ضوء ما درست. ٢٢– يمكن تحقيق عدة وظائف من دراستنا للاتجاهات، برهن على ذلك، . ٢٣– عرض باختصار مكونات الإتجاه ، ٢٤- أعط موافق حياتية تبرز فيها مكونات الاتجاه. ٢٥– هل تعتقد أنه يمكن البده بأي من مكونات الاتجاه دون ترتيب ؟..علل لما نقول، فمهمك لعوامل تغيير الاتجاه ،ما العوامل التي تؤدي إلى صعوبة أوسهولة تغريها.برر لمأ تقول، . - عرف مفهوم التوافق، ٢٦– يتضمن التوافق كما يستخدم فى علم النفس معنيين رئيسيين، اعرض في ضوء ما درست، ٢٧– عرف كل من (التوافق النفسي، التوافق الاجتماعي)، . ٢٨– ميز بين كل من التوافق النفسي والاجتماعي، ٢٩– عرف مفهوم الإحباط، ٠ـة – عارض العوامل المحدثة للإحباط، ا عرضا، ناقش، يوقف شعور الفرد بالإحباط على عدد من العوامل، ناقش، ى تعرف على الإحباط والصراع نتائج متعددة.ناقش، ٢ـة – تعدد أنوع الصراعات وفقًا للموقوف الذي يحدث فيه.اعرضر بإيجاز، ءـة – تعدد أنوع الصراعات وفقًا للموقوف الذي يحدث فيه.ناقش، هـة – اعيط مثلاأ لأنواع الصراعات وفقًا للموقوف الذي يحدث فيه، يتربب علي الإحباط والصراع نتائج متعددة.ناقش، ٣ـة – يترتب عليك الإحباط والصراع نتائج متعددة.أكد صدق العبارة، ٤ـة – اعرصر لنبعض الموافق الحياتية للتتابع المتربتي على تعرض الفرد للإحباطوالصراعات، ٥ـة – بين دور أساليب التوافق المباشرة في التغلب على الإحباط والصراعات التي يتعرض لها الفرد.\\n٢٠–هـ اعط مواقف حياتية لأساليب التوافق المباشرة في التغلب على الإحباطات والصراعات التي يتعرض لها الفرد. ١٨–مِيز بين الإحباط والتصراع، ٣٩–برر لماذا يعد القلق عرض رئيسي مشترك للاضطرابات الانفعاليَّة، ؟ هـ-عرف مفهم القلق. ٤٥–تتعدد مظاهر القلق.اعط مثالًا يوضح ذلك، ٦٧–هل تعتقد أن مستويات القلق ترتبط بالتوافق النفسي والإجتماعي؟ برر وجهة نظرك ٧٨–بعد ارتفاع مستوى القلق، وعدم القدرة على مواجهة بعض المشكلات مبرر لاستخدام حيل الدفاع.هل توافق علي ذلك؟ علل لوجهة نظرك، ٩ٔ–اهـ اعرض بإنجاز لحيل الدفاع، ١٠٠–ميز بإنجاز بين حيل الدفاع، ٢١–احيل الدفع متتفس انفعالي لاضبطريات الفرد.ناقش، ٢٢– تعد حيل الدفع سلاح ذو حدين .هل توافق علي ذلك؟ ٢٩–ماننتائج المترتبة علي فضل أساليب التوافق المباشرة في حل الصراعات وإلحباطات التي تواجه القرد؟\\nعلم الاجتماع',\n",
       " 'qa_output': 'Q1: What are the direct methods to overcome conflicts and frustrations?\\n\\nQ2: What is the concept of \"replacement\" in psychology?\\n\\nQ3: What is the difference between psychological and social compatibility?\\n\\nQ4: What is the definition of frustration according to the text?\\n\\nQ5: What are some examples of defensive mechanisms mentioned in the text?\\n\\nQ6: What is the purpose of studying personality types?\\n\\nQ7: Can a person\\'s personality be determined by their physical characteristics? Why or why not?\\n\\nQ8: What is the difference between psychological and social compatibility?\\n\\nQ9: What are some consequences of frustration and conflict?\\n\\nQ10: What are some examples of direct methods to overcome conflicts and frustrations mentioned in the text?',\n",
       " 'parsed_qa': []}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.strategy=question_strategy\n",
    "processor.execute_task(individual_documents[0],10,complexity='simple')\n",
    "# doc, questions, complexity='simple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e86984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processor.strategy=chatting_strategy \n",
    "# processor.execute_task(\"Which translator charges users with credits?\")\n",
    "# end=time.time()\n",
    "# print(\"Time Taken to process:  \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91545baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Query embedding final shape: (1, 384)\n",
      "[DEBUG] Index dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'similarity': 0.28096646070480347}, page_content='This feature enables users to compare, review, and edit translations in real time, enhancing accuracy and usability for both professional and casual users. These recommended features address critical gaps in current tools, such as limited editing capabilit ies, lack of flexible OCR options, insufficient support for domain -specific or tone - adjusted translations, absence of advanced translation modes, and the need for intuitive review interfaces. Implementing these enhancements could significantly improve the functionality and market competitiveness of document translation tools.'),\n",
       " Document(metadata={'similarity': 0.19255179166793823}, page_content='• 5 editable file translations per user/month in tota l. • Upload files up to 10 MB • Tone /informal tone is available . Pro Advanced $28.74/user/ month (Paid annually ) For individuals & teams • 20 files/month . • 5 editable file translations per user/month in tota l. • Upload files up to 20 MB . • Tone /informal tone is available . Pro Ultimate $57.49 /user/ month (Paid annually ) For individuals & teams • 20 files/month . • 5 editable file translations per user/month in tota l. • Upload files up to 20 MB . • Tone /informal tone is available . Doclingo Premium 7-Day $2.29/7 -Day • 250,000 chars. Monthly limit. • No daily limit . • No number of tra ns. Limit. • File size: 500 MB . • Trans. Engine : ChatGPT/Gemini /Deepseek/Claude . Premium + 7- Day $2.99/7-Day • 500,000 chars. Monthly limit • No daily limit . • No number of tra ns. Limit. • File size: 500 MB . • Trans. Engine : ChatGPT/Gemini /Deepseek/Claude . Premium 30- Day $7.59/M • 1M chars. Monthly limit'),\n",
       " Document(metadata={'similarity': 0.1843949407339096}, page_content='Offer a selection of LLMs ca tegorized by subscription plans to accommodate varying user needs and budgets. 2. AI PDF Summarization: Provide automated summarization of PDF content, enabling users to quickly grasp key points without reading entire documents. 3. AI Question Generator: Generat e relevant questions based on PDF content, supporting educational, training, or analytical use cases. 4. AI Instructions: Allow users to input custom prompts or guidelines for the AI engine to follow during translation, ensuring translations align with specif ic requirements or preferences. 5. Domain -Specific Translation: Incorporate smart detection or a predefined list of domains (e.g., banking, accounting, law, physics) to enhance translation accuracy for specialized documents. 6. Tone Customization: Enable smart d etection or manual selection of tone (e.g., formal, friendly) to tailor translations to the intended audience or context.'),\n",
       " Document(metadata={'similarity': 0.18026694655418396}, page_content='• Process Modes 1. Professional Translation: The AI automatically selects the optimal style and format for the translation based on the do cument’s context, audience, and purpose. For example, legal documents would adopt a formal tone with precise terminology, while marketing materials might use a persuasive, audience -friendly style, ensuring contextually appropriate and high - quality translat ions. 2. Paraphrase: Rephrase text or specific sections of a document while preserving the original meaning. This mode is ideal for simplifying complex text, adapting content for different audiences, or avoiding repetitive phrasing, such as rephrasing a techn ical manual for non - expert readers . • Split -View Translation Interface Provide a split -screen interface displaying the original document on the left and the translated document on the right, with synchronized page -by-page scrolling similar to a PDF viewer. This feature enables users to compare, review, and edit translations in real time, enhancing accuracy and usability for both professional and casual users'),\n",
       " Document(metadata={'similarity': 0.17683957517147064}, page_content='TranslaDocs • Cons: o No OCR support . o No Arabic language support . SmallPDF • Cons: o No OCR support . Doclingo • Pros: o Supports OCR . o Good performance for Arabic to English scanned documents . • Cons: o Fails with complex image tables . o Does not preserve RTL when translating from English to Arabic . DeepL • Pros: o Excellent performance for English OCR . • Cons: o Does not support Arabic OCR. Translated documents can be found here : DeepL Summary of Findings: The tools demonstrated varied performance across key criteria. Some excelled in specific areas, such as translation accuracy or affordability, while others lagged in advanced features like robust language support or seamless integration with existing workf lows. Pricing models also ranged widely, catering to different user segments from cost -conscious individuals to enterprises requiring premium functionalities.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fais_improved.get_relevant_documents(\"Editiors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffb3c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(processor.strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0417164f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Query embedding final shape: (1, 384)\n",
      "[DEBUG] Index dimension: 384\n",
      "**Main Topic:** AI Enhancements for PDF Translation and Management\n",
      "\n",
      "**Key Points:**\n",
      "\n",
      "* The document highlights various AI-powered features for enhancing PDF translation and management, including LLMs, automated summarization, question generation, tone customization, and domain-specific translation.\n",
      "* The features are designed to cater to different user needs and budgets, with options for professional translation, paraphrasing, and split-view translation interfaces.\n",
      "* The tools tested include Doctranslator, Doctranslate.io, TranslaDocs, SmallPDF, Doclingo, and DeepL, which demonstrated varying performance across key criteria such as OCR support, language support, and translation accuracy.\n",
      "\n",
      "**Supporting Details:**\n",
      "\n",
      "* Some AI-powered features include:\n",
      "\t+ LLMs for categorizing subscription plans to accommodate user needs and budgets\n",
      "\t+ Automated summarization of PDF content for quick grasping of key points\n",
      "\t+ Question generation based on PDF content for educational or analytical use cases\n",
      "\t+ Tone customization for tailoring translations to the intended audience or context\n",
      "* The tools tested demonstrated varying performance across key criteria, with some excelling in specific areas and others lagging behind.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "The AI-powered features and tools discussed in this document aim to enhance PDF translation and management by providing users with a range of options for customizing their experience. While the tools tested showed varying levels of performance, they demonstrate the potential for AI-driven solutions to improve the efficiency and accuracy of PDF-related tasks.\n"
     ]
    }
   ],
   "source": [
    "processor.strategy=rag_summary\n",
    "summary=processor.execute_task(\"Ai enhancments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fbc482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Summarization_Rag_Strategy object at 0x37f09cf40>\n",
      "[DEBUG] Query embedding final shape: (1, 384)\n",
      "[DEBUG] Index dimension: 384\n",
      "**Main Topic:** Use Cases for Translation Tools\n",
      "\n",
      "**Key Points:**\n",
      "\n",
      "* The effectiveness of translation tools varies across different criteria such as OCR support, language support, and performance.\n",
      "* Some tools excel in specific areas, while others struggle with complex image tables or lack of Arabic OCR support.\n",
      "* Pricing models differ widely, catering to various user segments from cost-conscious individuals to enterprises.\n",
      "\n",
      "**Supporting Details:**\n",
      "\n",
      "* The tested tools include Doctranslator, Doctranslate.io, TranslaDocs, SmallPDF, Doclingo, and DeepL.\n",
      "* Key features critical to the target audience's needs were evaluated across Arabic, French, and English languages.\n",
      "* The results comparison table highlights the strengths and weaknesses of each tool in terms of layout preservation, OCR support, pricing, and notes on specific issues.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "The use cases for translation tools highlight the importance of considering various factors such as language support, OCR capabilities, and performance when selecting a tool. While some tools may excel in specific areas, others may struggle with complex image tables or lack of Arabic OCR support. It is essential to evaluate these factors carefully to ensure that the chosen tool meets the needs of the target audience.\n"
     ]
    }
   ],
   "source": [
    "print(processor.strategy)\n",
    "summary=processor.execute_task(\"use cases \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a5666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Query embedding final shape: (1, 384)\n",
      "[DEBUG] Index dimension: 384\n",
      "**Main Topic:** Executive Summary of Document Translation Tools\n",
      "\n",
      "**Key Points:**\n",
      "\n",
      "* The AI-powered document translation tool offers various process modes, including professional translation, paraphrasing, and split-view translation interface.\n",
      "* The tool supports bi-directional conversion between Word, PowerPoint, Excel, and PDF formats, as well as image translation and selective OCR activation.\n",
      "* Additional features include AI-powered summarization, question generation, tone customization, and domain-specific translation.\n",
      "\n",
      "**Supporting Details:**\n",
      "\n",
      "* The tool's professional translation mode can adopt different styles and formats based on the document's context, audience, and purpose.\n",
      "* The split-view translation interface allows users to compare, review, and edit translations in real-time.\n",
      "* The tool's conversion features enable seamless transitions between document types while preserving formatting and content integrity.\n",
      "\n",
      "**Conclusion:** This AI-powered document translation tool offers a range of advanced features that can enhance the accuracy, usability, and efficiency of document translation processes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"**Main Topic:** Executive Summary of Document Translation Tools\\n\\n**Key Points:**\\n\\n* The AI-powered document translation tool offers various process modes, including professional translation, paraphrasing, and split-view translation interface.\\n* The tool supports bi-directional conversion between Word, PowerPoint, Excel, and PDF formats, as well as image translation and selective OCR activation.\\n* Additional features include AI-powered summarization, question generation, tone customization, and domain-specific translation.\\n\\n**Supporting Details:**\\n\\n* The tool's professional translation mode can adopt different styles and formats based on the document's context, audience, and purpose.\\n* The split-view translation interface allows users to compare, review, and edit translations in real-time.\\n* The tool's conversion features enable seamless transitions between document types while preserving formatting and content integrity.\\n\\n**Conclusion:** This AI-powered document translation tool offers a range of advanced features that can enhance the accuracy, usability, and efficiency of document translation processes.\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.execute_task(\"Executaive summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17366bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Query embedding final shape: (1, 384)\n",
      "[DEBUG] Index dimension: 384\n",
      "**Main Topic:** Mention Translation tools\n",
      "\n",
      "**Key Points:**\n",
      "\n",
      "* The current document translation tools have limitations and gaps in their features, such as limited editing capabilities, lack of flexible OCR options, insufficient support for domain-specific translations, and absence of advanced translation modes.\n",
      "* To improve the functionality and market competitiveness of document translation tools, several recommended features can be added, including PDF editing, PDF annotations, split PDF, process modes (professional translation and paraphrase), and a split-view translation interface.\n",
      "\n",
      "**Supporting Details:**\n",
      "\n",
      "* The analysis reveals that no single tool fully meets all requirements for accurate, efficient, and cost-effective document translation across Arabic, French, and English.\n",
      "* Some tools have limitations in their OCR capabilities, layout preservation, and handling of mixed language content.\n",
      "* The recommended features aim to address the gaps identified in the tested tools and improve functionality, user experience, and translation quality.\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "* To provide high-quality and accurate document translations, it is essential to develop or enhance existing translation tools with advanced features that cater to different user needs and requirements.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'**Main Topic:** Mention Translation tools\\n\\n**Key Points:**\\n\\n* The current document translation tools have limitations and gaps in their features, such as limited editing capabilities, lack of flexible OCR options, insufficient support for domain-specific translations, and absence of advanced translation modes.\\n* To improve the functionality and market competitiveness of document translation tools, several recommended features can be added, including PDF editing, PDF annotations, split PDF, process modes (professional translation and paraphrase), and a split-view translation interface.\\n\\n**Supporting Details:**\\n\\n* The analysis reveals that no single tool fully meets all requirements for accurate, efficient, and cost-effective document translation across Arabic, French, and English.\\n* Some tools have limitations in their OCR capabilities, layout preservation, and handling of mixed language content.\\n* The recommended features aim to address the gaps identified in the tested tools and improve functionality, user experience, and translation quality.\\n\\n**Conclusion:**\\n\\n* To provide high-quality and accurate document translations, it is essential to develop or enhance existing translation tools with advanced features that cater to different user needs and requirements.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.execute_task(\"Translation tools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b9489c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Query embedding final shape: (1, 384)\n",
      "[DEBUG] Index dimension: 384\n",
      "Parsed response: {'answer': 'Translation platforms that can be considered based on the provided context are Doctranslator, Doctranslate.io, TranslaDocs, SmallPDF, Doclingo, and DeepL. These platforms offer various features such as translation, OCR, and editing capabilities.', 'reasoning': 'The context provides information about different document translation tools and their limitations. It highlights the need for a platform that can accurately translate documents in real-time, preserve layout, and handle OCR for scanned documents. The recommended features mentioned aim to address these gaps and improve functionality, user experience, and translation quality. By considering these platforms and their examples, we can identify the strengths and weaknesses of each tool.', 'sources': [1, 3, 4, 5], 'raw_response': 'RESPONSE:\\nTranslation platforms that can be considered based on the provided context are Doctranslator, Doctranslate.io, TranslaDocs, SmallPDF, Doclingo, and DeepL. These platforms offer various features such as translation, OCR, and editing capabilities.\\n\\nREASONING:\\nThe context provides information about different document translation tools and their limitations. It highlights the need for a platform that can accurately translate documents in real-time, preserve layout, and handle OCR for scanned documents. The recommended features mentioned aim to address these gaps and improve functionality, user experience, and translation quality. By considering these platforms and their examples, we can identify the strengths and weaknesses of each tool.\\n\\nSOURCES:\\n1, 3, 4, 5'}\n",
      "[DEBUG] Query embedding final shape: (1, 384)\n",
      "[DEBUG] Index dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer': 'Translation platforms that can be considered based on the provided context are Doctranslator, Doctranslate.io, TranslaDocs, SmallPDF, Doclingo, and DeepL. These platforms offer various features such as translation, OCR, and editing capabilities.',\n",
       " 'reasoning': 'The context provides information about different document translation tools and their limitations. It highlights the need for a platform that can accurately translate documents in real-time, preserve layout, and handle OCR for scanned documents. The recommended features mentioned aim to address these gaps and improve functionality, user experience, and translation quality. By considering these platforms and their examples, we can identify the strengths and weaknesses of each tool.',\n",
       " 'sources': [1, 3, 4, 5],\n",
       " 'raw_response': 'RESPONSE:\\nTranslation platforms that can be considered based on the provided context are Doctranslator, Doctranslate.io, TranslaDocs, SmallPDF, Doclingo, and DeepL. These platforms offer various features such as translation, OCR, and editing capabilities.\\n\\nREASONING:\\nThe context provides information about different document translation tools and their limitations. It highlights the need for a platform that can accurately translate documents in real-time, preserve layout, and handle OCR for scanned documents. The recommended features mentioned aim to address these gaps and improve functionality, user experience, and translation quality. By considering these platforms and their examples, we can identify the strengths and weaknesses of each tool.\\n\\nSOURCES:\\n1, 3, 4, 5',\n",
       " 'source_documents': [Document(metadata={'similarity': 0.5309079885482788}, page_content='This feature enables users to compare, review, and edit translations in real time, enhancing accuracy and usability for both professional and casual users. These recommended features address critical gaps in current tools, such as limited editing capabilit ies, lack of flexible OCR options, insufficient support for domain -specific or tone - adjusted translations, absence of advanced translation modes, and the need for intuitive review interfaces. Implementing these enhancements could significantly improve the functionality and market competitiveness of document translation tools.'),\n",
       "  Document(metadata={'similarity': 0.5237861275672913}, page_content='MARKET RESEARCH REPORT: ANALYSIS OF DOCUMENT TRANSLATION TOOLS Evaluating Leading Solutions for Multilingual Document Translation Mah inour Mohammad'),\n",
       "  Document(metadata={'similarity': 0.5052964687347412}, page_content='• Process Modes 1. Professional Translation: The AI automatically selects the optimal style and format for the translation based on the do cument’s context, audience, and purpose. For example, legal documents would adopt a formal tone with precise terminology, while marketing materials might use a persuasive, audience -friendly style, ensuring contextually appropriate and high - quality translat ions. 2. Paraphrase: Rephrase text or specific sections of a document while preserving the original meaning. This mode is ideal for simplifying complex text, adapting content for different audiences, or avoiding repetitive phrasing, such as rephrasing a techn ical manual for non - expert readers . • Split -View Translation Interface Provide a split -screen interface displaying the original document on the left and the translated document on the right, with synchronized page -by-page scrolling similar to a PDF viewer. This feature enables users to compare, review, and edit translations in real time, enhancing accuracy and usability for both professional and casual users'),\n",
       "  Document(metadata={'similarity': 0.4995311498641968}, page_content='Executive Summary This section provides a high -level overview of the findings from the market research. Key Findings • Doctranslator : Offers free services with good layout preservation for English to Arabic transla tions and effective handling of text directionality. However, it lacks OCR capabilities and struggles with mixed language content. • Doctranslate.io : Provides OCR functionality but suffers from slow processing time s and poor layout preservation. It also fails to translate Arabic numerals and mismanages mixed text directions. • TranslaDocs : Does not support OCR or Arabic language, limiting its applicability. • SmallPDF : Offers limited translation support and no OCR capabilities. • Doclingo : Supports OCR with good performance for Arabic to English scanned documents but struggles with complex image tables and RTL preservation in English to Arabic translations. • DeepL : Excellent for English OCR but does not s upport Arabic, making it unsuitable for this use case. Features to be added: The analysis reveals that no single tool fully meets all requirements for accurate, efficient, and cost - effective document translation across Arabic, French, and English, particularly for preserving layout and handling OCR for scanned documents'),\n",
       "  Document(metadata={'similarity': 0.49200525879859924}, page_content=\"Features to be added: The analysis reveals that no single tool fully meets all requirements for accurate, efficient, and cost - effective document translation across Arabic, French, and English, particularly for preserving layout and handling OCR for scanned documents. Based on the evaluation, several opportunities exist to enhance document translation tools to better serve B2B and B2C markets. The following recommended features aim to address ga ps identified in the tested tools and improve functionality, user experience, and translation quality: • Editing Capabilities 1. PDF Editing: Enable users to add text, shapes, images, and freehand annotations to PDFs, facilitating document customization and correction post -translation. 2. PDF Annotations: Provide tools to write, draw, and highlight directly on PDFs, enhancing collaboration and docu ment review processes. 3. Split PDF: Allow users to split a PDF into multiple PDFs, with each page saved as a separate file. Include advanced options, such as specifying page ranges or programmatic splitting (similar to Python's split() function), to offer fl exibility.\")],\n",
       " 'source_texts': ['This feature enables users to compare, review, and edit translations in real time, enhancing accuracy and usability for both professional and casual users. These recommended features address critical gaps in current tools, such as limited editing capabilit ies, lack of flexible OCR options, insufficient support for domain -specific or tone - adjusted translations, absence of advanced translation modes, and the need for intuitive review interfaces. Implementing these enhancements could significantly improve the functionality and market competitiveness of document translation tools.',\n",
       "  'MARKET RESEARCH REPORT: ANALYSIS OF DOCUMENT TRANSLATION TOOLS Evaluating Leading Solutions for Multilingual Document Translation Mah inour Mohammad',\n",
       "  '• Process Modes 1. Professional Translation: The AI automatically selects the optimal style and format for the translation based on the do cument’s context, audience, and purpose. For example, legal documents would adopt a formal tone with precise terminology, while marketing materials might use a persuasive, audience -friendly style, ensuring contextually appropriate and high - quality translat ions. 2. Paraphrase: Rephrase text or specific sections of a document while preserving the original meaning. This mode is ideal for simplifying complex text, adapting content for different audiences, or avoiding repetitive phrasing, such as rephrasing a techn ical manual for non - expert readers . • Split -View Translation Interface Provide a split -screen interface displaying the original document on the left and the translated document on the right, with synchronized page -by-page scrolling similar to a PDF viewer. This feature enables users to compare, review, and edit translations in real time, enhancing accuracy and usability for both professional and casual users',\n",
       "  'Executive Summary This section provides a high -level overview of the findings from the market research. Key Findings • Doctranslator : Offers free services with good layout preservation for English to Arabic transla tions and effective handling of text directionality. However, it lacks OCR capabilities and struggles with mixed language content. • Doctranslate.io : Provides OCR functionality but suffers from slow processing time s and poor layout preservation. It also fails to translate Arabic numerals and mismanages mixed text directions. • TranslaDocs : Does not support OCR or Arabic language, limiting its applicability. • SmallPDF : Offers limited translation support and no OCR capabilities. • Doclingo : Supports OCR with good performance for Arabic to English scanned documents but struggles with complex image tables and RTL preservation in English to Arabic translations. • DeepL : Excellent for English OCR but does not s upport Arabic, making it unsuitable for this use case. Features to be added: The analysis reveals that no single tool fully meets all requirements for accurate, efficient, and cost - effective document translation across Arabic, French, and English, particularly for preserving layout and handling OCR for scanned documents',\n",
       "  \"Features to be added: The analysis reveals that no single tool fully meets all requirements for accurate, efficient, and cost - effective document translation across Arabic, French, and English, particularly for preserving layout and handling OCR for scanned documents. Based on the evaluation, several opportunities exist to enhance document translation tools to better serve B2B and B2C markets. The following recommended features aim to address ga ps identified in the tested tools and improve functionality, user experience, and translation quality: • Editing Capabilities 1. PDF Editing: Enable users to add text, shapes, images, and freehand annotations to PDFs, facilitating document customization and correction post -translation. 2. PDF Annotations: Provide tools to write, draw, and highlight directly on PDFs, enhancing collaboration and docu ment review processes. 3. Split PDF: Allow users to split a PDF into multiple PDFs, with each page saved as a separate file. Include advanced options, such as specifying page ranges or programmatic splitting (similar to Python's split() function), to offer fl exibility.\"]}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.strategy=chatting_strategy\n",
    "processor.execute_task(\"Translation platforms and their examples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5874e4d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run() got an unexpected keyword argument 'length'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, document \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(individual_documents):\n\u001b[1;32m      4\u001b[0m     doc_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlong\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     doc_end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] processing time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc_end_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mdoc_start_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 18\u001b[0m, in \u001b[0;36mTaskProcessor.execute_task\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:      \u001b[38;5;66;03m# ✅ Add this check\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo strategy set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: run() got an unexpected keyword argument 'length'"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for index, document in enumerate(individual_documents):\n",
    "    doc_start_time = time.time()\n",
    "    \n",
    "    processor.execute_task(document,length='long',verbose=True)\n",
    "    \n",
    "    doc_end_time = time.time()\n",
    "    print(f\"Document[{index}] processing time: {doc_end_time - doc_start_time:.2f} seconds\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Total processing time:\", end_time - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0f6ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.QuestionStrategy object at 0x380610d30>\n"
     ]
    }
   ],
   "source": [
    "processor.strategy=question_strategy\n",
    "print(processor.strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8def0e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the 20 simple questions that test understanding of key facts and definitions based on the provided text:\n",
      "\n",
      "Q1: What is the primary focus of this market research report?\n",
      "Q2: Which languages are supported by the document translation tools evaluated in this report?\n",
      "Q3: What are the five test cases used to evaluate the document translation tools?\n",
      "Q4: Which tool lacks OCR capabilities?\n",
      "Q5: What is the main issue with Doctranslator's handling of mixed language content?\n",
      "Q6: Which tool provides OCR functionality but has slow processing times?\n",
      "Q7: What feature does TranslaDocs lack?\n",
      "Q8: Which tool offers limited translation support and no OCR capabilities?\n",
      "Q9: What is the primary limitation of Doclingo's performance in English to Arabic translations?\n",
      "Q10: Which tool excels in English OCR but does not support Arabic OCR?\n",
      "Q11: What are the three recommended editing features for document translation tools?\n",
      "Q12: What is the purpose of the \"Split PDF\" feature?\n",
      "Q13: Which tool provides a split-view translation interface?\n",
      "Q14: What is the main benefit of Doctranslate.io's Topup-50 plan?\n",
      "Q15: How many credits does the Personal Subscription plan provide per year?\n",
      "Q16: What is the maximum file size allowed for uploads in Doclingo's Premium 7-Day plan?\n",
      "Q17: Which tool has a processing time of 1-3 minutes for OCR-based translations?\n",
      "Q18: What is the primary limitation of TranslaDocs' performance in handling Arabic language content?\n",
      "Q19: How many characters are included in Doclingo's Premium + 30-Day plan?\n",
      "Q20: What is the main difference between Doctranslator and Doctranslate.io in terms of OCR support?\n",
      "[]\n",
      "Document[1] processing time: 20.36 seconds\n",
      "Here are the 20 questions:\n",
      "\n",
      "Q1: What is Monday.com?\n",
      "Q2: Which platform offers AI-powered drawing splitting and indexing?\n",
      "Q3: What is PMWeb's strong point in terms of cost control, scheduling, and portfolio-wide visibility?\n",
      "Q4: Which platform has a steep learning curve?\n",
      "Q5: What is Aconex's strength in structured communication, transmittals, and formal document control?\n",
      "Q6: Which platform offers automated submittals, AI-powered drawing management, and integrated bid handling?\n",
      "Q7: What is the main difference between Monday.com and Wrike?\n",
      "Q8: Which platform has a feature matrix that quantifies how well each platform supports a core set of functionalities?\n",
      "Q9: What is Procore's unique selling point in terms of construction-focused toolkit?\n",
      "Q10: Which platform offers OCR-based document processing?\n",
      "Q11: What is the primary function of Ra Power Management (RaPM)?\n",
      "Q12: Which platform has a role-based task assignment feature?\n",
      "Q13: What is the main difference between Aconex and Procore?\n",
      "Q14: Which platform has a strong point in terms of financial oversight?\n",
      "Q15: What is Monday.com's strength in terms of dashboards for tracking deadlines and project progress?\n",
      "Q16: Which platform offers version control and submittal coordination features?\n",
      "Q17: What is the primary function of SenseHawk?\n",
      "Q18: Which platform has a feature that allows users to compare any two revisions on-screen?\n",
      "Q19: What is PMWeb's strength in terms of portfolio-wide visibility?\n",
      "Q20: Which platform has a feature that tracks status in real-time, updating fields like \"Submitted for Review\" or \"Approved\"?\n",
      "[]\n",
      "Document[2] processing time: 25.35 seconds\n",
      "Time Taken to process:   45.715123891830444\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "for index, document in enumerate(individual_documents):\n",
    "    doc_start_time = time.time()\n",
    "    processor.execute_task(document,20)\n",
    "    doc_end_time = time.time()\n",
    "    print(f\"Document[{index+1}] processing time: {doc_end_time - doc_start_time:.2f} seconds\")\n",
    "end=time.time()\n",
    "print(\"Time Taken to process:  \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f63bdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'challenshing' matched to 'challenging' (87% confidence)\n",
      "Here are the 20 complex questions based on the provided text:\n",
      "\n",
      "Q1: What are the key features evaluated in this market research report to assess document translation tools?\n",
      "\n",
      "Q2: Which tool offers free services with good layout preservation for English to Arabic translations and effective handling of text directionality?\n",
      "\n",
      "Q3: How does Doctranslator handle mixed language content, and what limitations does it have?\n",
      "\n",
      "Q4: What are the test cases conducted for each language in this report, and why are they important?\n",
      "\n",
      "Q5: Which tool provides OCR functionality but suffers from slow processing times and poor layout preservation?\n",
      "\n",
      "Q6: What is the main limitation of TranslaDocs, according to this report?\n",
      "\n",
      "Q7: How does SmallPDF handle translation support, and what are its limitations?\n",
      "\n",
      "Q8: What are the recommended features for enhancing document translation tools, as suggested in this report?\n",
      "\n",
      "Q9: How can AI-powered features improve the functionality of document translation tools?\n",
      "\n",
      "Q10: Which tool is excellent for English OCR but does not support Arabic OCR?\n",
      "\n",
      "Q11: What are the benefits and drawbacks of using Doctranslate.io's Topup plans?\n",
      "\n",
      "Q12: How do the pricing models of different tools cater to different user segments?\n",
      "\n",
      "Q13: What are the key findings from this market research report, and what implications do they have for document translation tool development?\n",
      "\n",
      "Q14: Which tool offers good performance for Arabic to English scanned documents but struggles with complex image tables?\n",
      "\n",
      "Q15: What is the main advantage of using Doclingo's Premium plans?\n",
      "\n",
      "Q16: How does the AI-powered summarization feature in this report support users' needs?\n",
      "\n",
      "Q17: What are the limitations of Doctranslator when translating from Arabic to English, and how do they impact its overall performance?\n",
      "\n",
      "Q18: Which tool provides a split-view translation interface for comparing and reviewing translations?\n",
      "\n",
      "Q19: What are the key differences between Doctranslate.io's Pro Starter and Pro Advanced plans?\n",
      "\n",
      "Q20: How can domain-specific translation features improve the accuracy of document translation tools?\n",
      "[]\n",
      "Document[1] processing time: 21.90 seconds\n",
      "'challenshing' matched to 'challenging' (87% confidence)\n",
      "Here are 20 complex questions that require critical thinking, analysis, and synthesis of information based on the provided text:\n",
      "\n",
      "Q1: What are the primary differences between Monday.com, Wrike, PMWeb, Aconex, and Procore in terms of their project management capabilities?\n",
      "\n",
      "Q2: How do the various platforms handle document approval workflows, and what are the implications for construction projects?\n",
      "\n",
      "Q3: What role does version control play in each platform's approach to managing documents, and how does this impact collaboration among stakeholders?\n",
      "\n",
      "Q4: Can you explain the concept of \"submittals\" in Procore, and how it differs from traditional project management tools?\n",
      "\n",
      "Q5: How do PMWeb, Aconex, and Procore support financial oversight and cost control for construction projects, and what are their respective strengths and limitations?\n",
      "\n",
      "Q6: What is the significance of \"bid management\" in Procore, and how does this feature impact the bidding process for construction projects?\n",
      "\n",
      "Q7: Can you compare and contrast the document management systems (DMS) offered by Monday.com, Wrike, PMWeb, Aconex, and Procore?\n",
      "\n",
      "Q8: How do the various platforms handle notifications and alerts, and what are the implications for project managers and stakeholders?\n",
      "\n",
      "Q9: What is the importance of \"project archiving\" in each platform's approach to managing construction projects, and how does this feature impact long-term project management?\n",
      "\n",
      "Q10: Can you explain the concept of \"overlaying drawings\" in Procore, and how this feature impacts the review process for construction projects?\n",
      "\n",
      "Q11: How do PMWeb, Aconex, and Procore support role-based task assignment and workflow approvals for construction projects?\n",
      "\n",
      "Q12: What are the primary differences between Monday.com and Wrike in terms of their project management capabilities, and which platform is more suitable for construction projects?\n",
      "\n",
      "Q13: Can you compare and contrast the reporting features offered by PMWeb, Aconex, and Procore, and what are the implications for project managers and stakeholders?\n",
      "\n",
      "Q14: How do the various platforms handle change orders and revisions in construction projects, and what are their respective strengths and limitations?\n",
      "\n",
      "Q15: What is the significance of \"AI-powered drawing management\" in Procore, and how does this feature impact the review process for construction projects?\n",
      "\n",
      "Q16: Can you explain the concept of \"transmittals\" in Aconex, and how this feature impacts the communication process for construction projects?\n",
      "\n",
      "Q17: How do PMWeb, Aconex, and Procore support collaboration among stakeholders, including contractors, consultants, and clients?\n",
      "\n",
      "Q18: What are the primary differences between Monday.com and Wrike in terms of their scalability and flexibility for large-scale construction projects?\n",
      "\n",
      "Q19: Can you compare and contrast the cost control features offered by PMWeb, Aconex, and Procore, and what are the implications for project managers and stakeholders?\n",
      "\n",
      "Q20: How do the various platforms handle project scheduling and resource allocation for construction projects, and what are their respective strengths and limitations?\n",
      "[]\n",
      "Document[2] processing time: 35.65 seconds\n",
      "Time Taken to process:   57.5525918006897\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "for index, document in enumerate(individual_documents):\n",
    "    doc_start_time = time.time()\n",
    "    processor.execute_task(document,20,'challenshing')\n",
    "    doc_end_time = time.time()\n",
    "    print(f\"Document[{index+1}] processing time: {doc_end_time - doc_start_time:.2f} seconds\")\n",
    "end=time.time()\n",
    "print(\"Time Taken to process:  \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea967662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 20 simple and basic questions that test understanding of key facts and definitions based on the provided text:\n",
      "\n",
      "Q1: What is the main focus of this market research report?\n",
      "Q2: Which languages are supported by the document translation tools evaluated in this report?\n",
      "Q3: What are the key features evaluated in this report?\n",
      "Q4: What is OCR (Optical Character Recognition) support, and which tool lacks it?\n",
      "Q5: Which tool offers free services with good layout preservation for English to Arabic translations?\n",
      "Q6: What is the main limitation of Doctranslator's OCR capabilities?\n",
      "Q7: Which tool provides OCR functionality but suffers from slow processing times?\n",
      "Q8: What is the primary issue with TranslaDocs' translation accuracy?\n",
      "Q9: Which tool does not support Arabic language or OCR?\n",
      "Q10: What is the pricing model for SmallPDF?\n",
      "Q11: Which tool supports OCR with good performance for Arabic to English scanned documents?\n",
      "Q12: What is the main limitation of Doclingo's OCR capabilities?\n",
      "Q13: Which tool offers excellent performance for English OCR but does not support Arabic OCR?\n",
      "Q14: What are the five recommended features for document translation tools?\n",
      "Q15: What is the purpose of the \"Chat with PDF\" feature in AI-Powered Features?\n",
      "Q16: Which tool provides a split-view translation interface?\n",
      "Q17: What is the main benefit of the \"Professional Translation\" process mode?\n",
      "Q18: Which tool offers a personal subscription plan?\n",
      "Q19: What is the maximum file size for uploading files to Doclingo Premium plans?\n",
      "Q20: Which tool has a monthly limit of 2M chars in its Premium + 30-Day plan?\n",
      "[]\n",
      "Document[1] processing time: 19.84 seconds\n",
      "Here are 20 simple questions that test understanding of key facts and definitions based on the provided text:\n",
      "\n",
      "Q1: What is the primary function of Monday.com?\n",
      "Q2: Which platform has a strong focus on cost control, scheduling, and portfolio-wide visibility?\n",
      "Q3: What is the main difference between Wrike and PMWeb?\n",
      "Q4: How does Aconex differ from Procore in terms of its features?\n",
      "Q5: What is the primary function of Ra Power Management (RaPM)?\n",
      "Q6: Which platform has a feature called \"Auto-changing status after submittals\"?\n",
      "Q7: What is the main difference between Monday.com and Wrike in terms of their features?\n",
      "Q8: How does Procore's Submittal Builder work?\n",
      "Q9: What is the purpose of the Specification Book in Procore?\n",
      "Q10: Which platform has a feature called \"Markup versions\"?\n",
      "Q11: What is the primary function of Payaca?\n",
      "Q12: How does Aconex handle formal document control and transmittals?\n",
      "Q13: What is the main difference between PMWeb and Procore in terms of their features?\n",
      "Q14: How does Monday.com support financial oversight?\n",
      "Q15: Which platform has a feature called \"Bids management\"?\n",
      "Q16: What is the primary function of SenseHawk?\n",
      "Q17: How does Wrike handle role assignment and approval workflows?\n",
      "Q18: What is the main difference between Procore and Aconex in terms of their features?\n",
      "Q19: How does PMWeb support project archiving?\n",
      "Q20: Which platform has a feature called \"Drawings tool\" with OCR engine?\n",
      "[]\n",
      "Document[2] processing time: 25.23 seconds\n",
      "Time Taken to process:   45.07068204879761\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "for index, document in enumerate(individual_documents):\n",
    "    doc_start_time = time.time()\n",
    "    processor.execute_task(document,20,'simple')\n",
    "    doc_end_time = time.time()\n",
    "    print(f\"Document[{index+1}] processing time: {doc_end_time - doc_start_time:.2f} seconds\")\n",
    "end=time.time()\n",
    "print(\"Time Taken to process:  \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4b6641",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
