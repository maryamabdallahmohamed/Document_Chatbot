{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92876b39",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a52a1cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import faiss\n",
    "import time\n",
    "import yaml\n",
    "import re\n",
    "from pathlib import Path\n",
    "from abc import ABC, abstractmethod\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore import InMemoryDocstore\n",
    "from langchain.llms import Ollama\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e068f9",
   "metadata": {},
   "source": [
    "## Abstract classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2b30a8",
   "metadata": {},
   "source": [
    "### Preprocessing class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7caedd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class BasePreprocessor(ABC):\n",
    "    def __init__(self):\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=200,\n",
    "            chunk_overlap=50, \n",
    "            length_function=lambda x: len(x.split()),\n",
    "            separators=[\"\\n\\n\\n\", \"\\n\\n\", \"\\n\", \". \", \"! \", \"? \", \"; \", \", \", \" \", \"\"],\n",
    "            keep_separator=False,\n",
    "            add_start_index=True,\n",
    "            strip_whitespace=True\n",
    "        )\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_and_preprocess_data(self, file_path):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def process_documents_from_files(self, file_paths):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def clean_text(self, text):\n",
    "        return re.sub(r'\\s+', ' ', re.sub(r'\\n{3,}', '\\n\\n', str(text))).strip()\n",
    "\n",
    "\n",
    "\n",
    "    def chunk_documents(self, individual_documents):\n",
    "        chunked_docs = []\n",
    "        for doc in individual_documents:\n",
    "            chunks = self.text_splitter.split_text(doc.page_content)\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                chunked_docs.append(\n",
    "                    Document(\n",
    "                        page_content=chunk,\n",
    "                        metadata={\n",
    "                            \"pdf_id\": doc.metadata[\"pdf_id\"],\n",
    "                            \"chunk_id\": i\n",
    "                        }\n",
    "                    )\n",
    "                )\n",
    "        print(f\"✅ Total Chunks: {len(chunked_docs)}\")\n",
    "        return chunked_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23e66d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSONPreprocessor(BasePreprocessor):\n",
    "    def load_and_preprocess_data(self, file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            raw_data = json.load(f)\n",
    "        clean_texts = [self.clean_text(entry) for entry in raw_data if isinstance(entry, str)]\n",
    "        return \"\\n\".join(clean_texts)\n",
    "    def process_documents_from_files(self, file_paths):\n",
    "        documents = []\n",
    "\n",
    "        for i, file_path in enumerate(file_paths):\n",
    "            text = self.load_and_preprocess_data(file_path).strip()\n",
    "            documents.append(\n",
    "                Document(page_content=text, metadata={\"pdf_id\": i})\n",
    "            )\n",
    "\n",
    "        return documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c8bf9b",
   "metadata": {},
   "source": [
    "### Embeddings Abstract class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80805382",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(ABC): \n",
    "    def __init__(self, model_name, batch_size):\n",
    "        self.model_name = model_name\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        self.device = (\n",
    "            'cuda' if torch.cuda.is_available()\n",
    "            else 'mps' if torch.backends.mps.is_available()\n",
    "            else 'cpu'\n",
    "        )\n",
    "        self.embedding_model = HuggingFaceEmbeddings(model_name=model_name,model_kwargs={'device': self.device},encode_kwargs={'normalize_embeddings': True},multi_process=True,\n",
    "                                                     show_progress=True,cache_folder='./embedder_model_cache')\n",
    "\n",
    "    @abstractmethod\n",
    "    def embed_documents(self, documents):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def batch_embed(self, texts, batch_size=None): \n",
    "        pass\n",
    "\n",
    "class MultilingualEmbedder(Embedder): \n",
    "    def __init__(self, model_name, batch_size):\n",
    "        super().__init__(model_name, batch_size)\n",
    "\n",
    "    def embed_documents(self, documents):\n",
    "        return self.batch_embed(documents, batch_size=self.batch_size)\n",
    "\n",
    "    def batch_embed(self, texts, batch_size=None):\n",
    "        if batch_size is None:\n",
    "            batch_size = self.batch_size\n",
    "        \n",
    "        embeddings = []\n",
    "        for i in range(0, len(texts), batch_size):\n",
    "            batch = texts[i:i + batch_size]\n",
    "            batch_embeddings = self.embedding_model.embed_documents(batch)\n",
    "            embeddings.extend(batch_embeddings)\n",
    "        \n",
    "        return np.array(embeddings, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22818acf",
   "metadata": {},
   "source": [
    "### Faiss Abstract class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89195008",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorStoreBase(ABC):\n",
    "    @abstractmethod\n",
    "    def create_vector_store(self, documents, embedder_model):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def get_relevant_documents(self, query, top_k=5):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def save_index(self, file_path):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def load_index(self, file_path):\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1ce8c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FAISSBasic(VectorStoreBase):\n",
    "    def __init__(self, embedder_model=None):\n",
    "        self.index = None\n",
    "        self.chunks_dict = None\n",
    "        self.dimension = None\n",
    "        self.total_vectors = 0\n",
    "        self.index_type = \"IndexFlatIP\"\n",
    "        self.embedder_model = embedder_model\n",
    "    \n",
    "    def create_vector_store(self, documents, embedder_model=None):\n",
    "        \"\"\"Create vector store from documents\"\"\"\n",
    "        if embedder_model:\n",
    "            self.embedder_model = embedder_model\n",
    "        \n",
    "        if not self.embedder_model:\n",
    "            raise ValueError(\"Embedder model is required\")\n",
    "        \n",
    "        texts = [doc.page_content for doc in documents]\n",
    "        embeddings = self.embedder_model.batch_embed(texts)\n",
    "        embeddings = np.array(embeddings).astype(\"float32\")\n",
    "        \n",
    "        # Ensure embeddings are 2D\n",
    "        if embeddings.ndim == 1:\n",
    "            embeddings = embeddings.reshape(1, -1)\n",
    "        \n",
    "        self.dimension = embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatIP(self.dimension)\n",
    "        self.index.add(embeddings)\n",
    "        \n",
    "        # Store text chunks with their indices\n",
    "        self.chunks_dict = {i: text for i, text in enumerate(texts)}\n",
    "        self.total_vectors = self.index.ntotal\n",
    "        \n",
    "        print(f\"[FAISS] Created index with {self.total_vectors} vectors of dim {self.dimension}\")\n",
    "        return self\n",
    "    \n",
    "    def get_relevant_documents(self, query, top_k=5):\n",
    "        \"\"\"Main retriever function - returns LangChain Document objects\"\"\"\n",
    "        if self.index is None:\n",
    "            raise ValueError(\"Index not created. Call create_vector_store() first.\")\n",
    "        \n",
    "        if not self.embedder_model:\n",
    "            raise ValueError(\"Embedder model not set\")\n",
    "        \n",
    "        # Get query embedding\n",
    "        if isinstance(query, str):\n",
    "            query_embedding = self.embedder_model.batch_embed([query])\n",
    "            if isinstance(query_embedding, list) and len(query_embedding) > 0:\n",
    "                query_embedding = query_embedding[0]\n",
    "            elif isinstance(query_embedding, np.ndarray) and query_embedding.ndim > 1:\n",
    "                query_embedding = query_embedding[0]\n",
    "        else:\n",
    "            query_embedding = self.embedder_model.batch_embed(query)\n",
    "        \n",
    "        # Search and format results\n",
    "        results = self._search_chunks(query_embedding, top_k)\n",
    "        \n",
    "        return [\n",
    "            Document(page_content=res['text'], metadata={\"similarity\": res['similarity']})\n",
    "            for res in results\n",
    "        ]\n",
    "    \n",
    "    def _search_chunks(self, query_embedding, top_k=5):\n",
    "        \"\"\"Internal search function - returns raw results\"\"\"\n",
    "        # Ensure query_embedding is properly shaped\n",
    "        query_embedding = np.array(query_embedding).astype(\"float32\")\n",
    "        \n",
    "        # Handle different input shapes\n",
    "        if query_embedding.ndim == 1:\n",
    "            query_embedding = query_embedding.reshape(1, -1)\n",
    "        elif query_embedding.ndim > 2:\n",
    "            query_embedding = query_embedding.reshape(1, -1)\n",
    "        \n",
    "        print(f\"[DEBUG] Query embedding final shape: {query_embedding.shape}\")\n",
    "        print(f\"[DEBUG] Index dimension: {self.dimension}\")\n",
    "        \n",
    "        # Verify dimensions match\n",
    "        if query_embedding.shape[1] != self.dimension:\n",
    "            raise ValueError(f\"Query embedding dimension {query_embedding.shape[1]} doesn't match index dimension {self.dimension}\")\n",
    "        \n",
    "        # Search FAISS index\n",
    "        distances, indices = self.index.search(query_embedding, top_k)\n",
    "        \n",
    "        # Format results\n",
    "        formatted = []\n",
    "        for i in range(top_k):\n",
    "            faiss_idx = indices[0][i]\n",
    "            if faiss_idx != -1 and faiss_idx < len(self.chunks_dict):\n",
    "                distance = distances[0][i]\n",
    "                formatted.append({\n",
    "                    'chunk_id': faiss_idx,\n",
    "                    'text': self.chunks_dict[faiss_idx],\n",
    "                    'distance': distance,\n",
    "                    'similarity': float(distance)  # For cosine similarity, higher is better\n",
    "                })\n",
    "        \n",
    "        return formatted\n",
    "    \n",
    "    def search_raw(self, query_embedding, top_k=5):\n",
    "        \"\"\"Search with raw embedding input - useful for advanced use cases\"\"\"\n",
    "        return self._search_chunks(query_embedding, top_k)\n",
    "    \n",
    "    def save_index(self, file_path):\n",
    "        \"\"\"Save both FAISS index and metadata\"\"\"\n",
    "        if self.index is None:\n",
    "            raise ValueError(\"No index to save\")\n",
    "        \n",
    "        # Save FAISS index\n",
    "        faiss.write_index(self.index, f\"{file_path}.faiss\")\n",
    "        \n",
    "        # Save metadata\n",
    "        metadata = {\n",
    "            'chunks_dict': self.chunks_dict,\n",
    "            'dimension': self.dimension,\n",
    "            'total_vectors': self.total_vectors,\n",
    "            'index_type': self.index_type\n",
    "        }\n",
    "        \n",
    "        with open(f\"{file_path}_metadata.pkl\", 'wb') as f:\n",
    "            pickle.dump(metadata, f)\n",
    "        \n",
    "        print(f\"[FAISS] Index and metadata saved to {file_path}\")\n",
    "    \n",
    "    def load_index(self, file_path, embedder_model=None):\n",
    "        \"\"\"Load both FAISS index and metadata\"\"\"\n",
    "        if not os.path.exists(f\"{file_path}.faiss\"):\n",
    "            raise FileNotFoundError(f\"Index file {file_path}.faiss not found\")\n",
    "        \n",
    "        if not os.path.exists(f\"{file_path}_metadata.pkl\"):\n",
    "            raise FileNotFoundError(f\"Metadata file {file_path}_metadata.pkl not found\")\n",
    "        \n",
    "        # Load FAISS index\n",
    "        self.index = faiss.read_index(f\"{file_path}.faiss\")\n",
    "        \n",
    "        # Load metadata\n",
    "        with open(f\"{file_path}_metadata.pkl\", 'rb') as f:\n",
    "            metadata = pickle.load(f)\n",
    "        \n",
    "        self.chunks_dict = metadata['chunks_dict']\n",
    "        self.dimension = metadata['dimension']\n",
    "        self.total_vectors = metadata['total_vectors']\n",
    "        self.index_type = metadata['index_type']\n",
    "        \n",
    "        # Set embedder model if provided\n",
    "        if embedder_model:\n",
    "            self.embedder_model = embedder_model\n",
    "        \n",
    "        print(f\"[FAISS] Index loaded: {self.total_vectors} vectors, dim {self.dimension}\")\n",
    "        return self\n",
    "    \n",
    "    def set_embedder_model(self, embedder_model):\n",
    "        \"\"\"Set or update the embedder model\"\"\"\n",
    "        self.embedder_model = embedder_model\n",
    "        return self\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get index statistics\"\"\"\n",
    "        return {\n",
    "            'total_vectors': self.total_vectors,\n",
    "            'dimension': self.dimension,\n",
    "            'index_type': self.index_type,\n",
    "            'has_embedder': self.embedder_model is not None\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ed1060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FAISSImproved(VectorStoreBase):\n",
    "    def __init__(self, embedder_model=None):\n",
    "        self.index = None\n",
    "        self.chunks_dict = None\n",
    "        self.dimension = None\n",
    "        self.total_vectors = 0\n",
    "        self.index_type = \"IndexFlatIP\"\n",
    "        self.embedder_model = embedder_model\n",
    "        # New attributes for enhanced functionality\n",
    "        self.docstore = None\n",
    "        self.index_to_docstore_id = None\n",
    "        self.documents = None  # Store original Document objects\n",
    "    \n",
    "    def create_vector_store(self, documents, embedder_model=None):\n",
    "        \"\"\"Create vector store from documents\"\"\"\n",
    "        if embedder_model:\n",
    "            self.embedder_model = embedder_model\n",
    "        \n",
    "        if not self.embedder_model:\n",
    "            raise ValueError(\"Embedder model is required\")\n",
    "        \n",
    "        texts = [doc.page_content for doc in documents]\n",
    "        embeddings = self.embedder_model.batch_embed(texts)\n",
    "        embeddings = np.array(embeddings).astype(\"float32\")\n",
    "        \n",
    "        # Ensure embeddings are 2D\n",
    "        if embeddings.ndim == 1:\n",
    "            embeddings = embeddings.reshape(1, -1)\n",
    "        \n",
    "        self.dimension = embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatIP(self.dimension)\n",
    "        self.index.add(embeddings)\n",
    "        \n",
    "        # Store text chunks with their indices\n",
    "        self.chunks_dict = {i: text for i, text in enumerate(texts)}\n",
    "        self.total_vectors = self.index.ntotal\n",
    "        \n",
    "        print(f\"[FAISS] Created index with {self.total_vectors} vectors of dim {self.dimension}\")\n",
    "        return self\n",
    "    \n",
    "    def create_vectorstore(self, docs, normalize_embeddings=True):\n",
    "        \"\"\"\n",
    "        Create a FAISS vector store from a list of Document objects.\n",
    "        Each document should have metadata like pdf_id, chunk_id, etc.\n",
    "        \n",
    "        Args:\n",
    "            docs: List of Document objects\n",
    "            normalize_embeddings: Whether to normalize embeddings for cosine similarity\n",
    "        \n",
    "        Returns:\n",
    "            self: Returns the FAISS instance for method chaining\n",
    "        \"\"\"\n",
    "        if not self.embedder_model:\n",
    "            raise ValueError(\"Embedder model is required. Set it during initialization or call set_embedder_model()\")\n",
    "        \n",
    "        # Extract texts from Document objects\n",
    "        texts = [doc.page_content for doc in docs]\n",
    "        \n",
    "        # Generate embeddings\n",
    "        embeddings = self.embedder_model.batch_embed(texts)\n",
    "        embeddings = np.array(embeddings).astype(\"float32\")\n",
    "        \n",
    "        # Ensure embeddings are 2D\n",
    "        if embeddings.ndim == 1:\n",
    "            embeddings = embeddings.reshape(1, -1)\n",
    "        \n",
    "        # Initialize FAISS Index\n",
    "        self.dimension = embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatIP(self.dimension)\n",
    "        \n",
    "        # Normalize embeddings for cosine similarity if requested\n",
    "        if normalize_embeddings:\n",
    "            faiss.normalize_L2(embeddings)\n",
    "        \n",
    "        self.index.add(embeddings)\n",
    "        \n",
    "        # Store original Document objects and create mappings\n",
    "        self.documents = docs\n",
    "        self.docstore = {str(i): doc for i, doc in enumerate(docs)}\n",
    "        self.index_to_docstore_id = {i: str(i) for i in range(len(docs))}\n",
    "        \n",
    "        # Also maintain backward compatibility with chunks_dict\n",
    "        self.chunks_dict = {i: doc.page_content for i, doc in enumerate(docs)}\n",
    "        self.total_vectors = self.index.ntotal\n",
    "        \n",
    "        print(f\"[FAISS] Created vectorstore with {self.total_vectors} documents of dim {self.dimension}\")\n",
    "        print(f\"[FAISS] Normalization: {'enabled' if normalize_embeddings else 'disabled'}\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def get_relevant_documents(self, query, top_k=5):\n",
    "        \"\"\"Main retriever function - returns LangChain Document objects\"\"\"\n",
    "        if self.index is None:\n",
    "            raise ValueError(\"Index not created. Call create_vector_store() or create_vectorstore() first.\")\n",
    "        \n",
    "        if not self.embedder_model:\n",
    "            raise ValueError(\"Embedder model not set\")\n",
    "        \n",
    "        # Get query embedding\n",
    "        if isinstance(query, str):\n",
    "            # Use embed_query if available, otherwise fall back to batch_embed\n",
    "            if hasattr(self.embedder_model, 'embed_query'):\n",
    "                query_embedding = self.embedder_model.embed_query(query)\n",
    "            else:\n",
    "                query_embedding = self.embedder_model.batch_embed([query])\n",
    "                if isinstance(query_embedding, list) and len(query_embedding) > 0:\n",
    "                    query_embedding = query_embedding[0]\n",
    "                elif isinstance(query_embedding, np.ndarray) and query_embedding.ndim > 1:\n",
    "                    query_embedding = query_embedding[0]\n",
    "        else:\n",
    "            query_embedding = self.embedder_model.batch_embed(query)\n",
    "        \n",
    "        # Search and format results\n",
    "        if self.docstore is not None:\n",
    "            # Use enhanced docstore-based retrieval\n",
    "            results = self._search_with_docstore(query_embedding, top_k)\n",
    "        else:\n",
    "            # Fall back to original chunk-based retrieval\n",
    "            results = self._search_chunks(query_embedding, top_k)\n",
    "            # Convert to Document objects for consistency\n",
    "            results = [\n",
    "                Document(page_content=res['text'], metadata={\"similarity\": res['similarity']})\n",
    "                for res in results\n",
    "            ]\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _search_with_docstore(self, query_embedding, top_k=5):\n",
    "        \"\"\"Enhanced search function using docstore - returns Document objects\"\"\"\n",
    "        # Ensure query_embedding is properly shaped\n",
    "        query_embedding = np.array(query_embedding).astype(\"float32\")\n",
    "        \n",
    "        # Handle different input shapes\n",
    "        if query_embedding.ndim == 1:\n",
    "            query_embedding = query_embedding.reshape(1, -1)\n",
    "        elif query_embedding.ndim > 2:\n",
    "            query_embedding = query_embedding.reshape(1, -1)\n",
    "        \n",
    "        # Verify dimensions match\n",
    "        if query_embedding.shape[1] != self.dimension:\n",
    "            raise ValueError(f\"Query embedding dimension {query_embedding.shape[1]} doesn't match index dimension {self.dimension}\")\n",
    "        \n",
    "        # Search FAISS index\n",
    "        distances, indices = self.index.search(query_embedding, top_k)\n",
    "        \n",
    "        # Format results using docstore\n",
    "        documents = []\n",
    "        for i in range(top_k):\n",
    "            faiss_idx = indices[0][i]\n",
    "            if faiss_idx != -1 and faiss_idx in self.index_to_docstore_id:\n",
    "                docstore_id = self.index_to_docstore_id[faiss_idx]\n",
    "                if docstore_id in self.docstore:\n",
    "                    doc = self.docstore[docstore_id]\n",
    "                    similarity = float(distances[0][i])\n",
    "                    \n",
    "                    # Create a copy of the document with updated metadata\n",
    "                    enhanced_metadata = doc.metadata.copy() if doc.metadata else {}\n",
    "                    enhanced_metadata[\"similarity\"] = similarity\n",
    "                    enhanced_metadata[\"retrieval_index\"] = faiss_idx\n",
    "                    \n",
    "                    enhanced_doc = Document(\n",
    "                        page_content=doc.page_content,\n",
    "                        metadata=enhanced_metadata\n",
    "                    )\n",
    "                    documents.append(enhanced_doc)\n",
    "        \n",
    "        return documents\n",
    "    \n",
    "    def _search_chunks(self, query_embedding, top_k=5):\n",
    "        \"\"\"Internal search function - returns raw results\"\"\"\n",
    "        # Ensure query_embedding is properly shaped\n",
    "        query_embedding = np.array(query_embedding).astype(\"float32\")\n",
    "        \n",
    "        # Handle different input shapes\n",
    "        if query_embedding.ndim == 1:\n",
    "            query_embedding = query_embedding.reshape(1, -1)\n",
    "        elif query_embedding.ndim > 2:\n",
    "            query_embedding = query_embedding.reshape(1, -1)\n",
    "        \n",
    "        print(f\"[DEBUG] Query embedding final shape: {query_embedding.shape}\")\n",
    "        print(f\"[DEBUG] Index dimension: {self.dimension}\")\n",
    "        \n",
    "        # Verify dimensions match\n",
    "        if query_embedding.shape[1] != self.dimension:\n",
    "            raise ValueError(f\"Query embedding dimension {query_embedding.shape[1]} doesn't match index dimension {self.dimension}\")\n",
    "        \n",
    "        # Search FAISS index\n",
    "        distances, indices = self.index.search(query_embedding, top_k)\n",
    "        \n",
    "        # Format results\n",
    "        formatted = []\n",
    "        for i in range(top_k):\n",
    "            faiss_idx = indices[0][i]\n",
    "            if faiss_idx != -1 and faiss_idx < len(self.chunks_dict):\n",
    "                distance = distances[0][i]\n",
    "                formatted.append({\n",
    "                    'chunk_id': faiss_idx,\n",
    "                    'text': self.chunks_dict[faiss_idx],\n",
    "                    'distance': distance,\n",
    "                    'similarity': float(distance)  # For cosine similarity, higher is better\n",
    "                })\n",
    "        \n",
    "        return formatted\n",
    "    \n",
    "    def search_raw(self, query_embedding, top_k=5):\n",
    "        \"\"\"Search with raw embedding input - useful for advanced use cases\"\"\"\n",
    "        return self._search_chunks(query_embedding, top_k)\n",
    "    \n",
    "    def save_index(self, file_path):\n",
    "        \"\"\"Save both FAISS index and metadata\"\"\"\n",
    "        if self.index is None:\n",
    "            raise ValueError(\"No index to save\")\n",
    "        \n",
    "        # Save FAISS index\n",
    "        faiss.write_index(self.index, f\"{file_path}.faiss\")\n",
    "        \n",
    "        # Save metadata (enhanced to include new attributes)\n",
    "        metadata = {\n",
    "            'chunks_dict': self.chunks_dict,\n",
    "            'dimension': self.dimension,\n",
    "            'total_vectors': self.total_vectors,\n",
    "            'index_type': self.index_type,\n",
    "            'docstore': self.docstore,\n",
    "            'index_to_docstore_id': self.index_to_docstore_id,\n",
    "            'documents': self.documents\n",
    "        }\n",
    "        \n",
    "        with open(f\"{file_path}_metadata.pkl\", 'wb') as f:\n",
    "            pickle.dump(metadata, f)\n",
    "        \n",
    "        print(f\"[FAISS] Index and metadata saved to {file_path}\")\n",
    "    \n",
    "    def load_index(self, file_path, embedder_model=None):\n",
    "        \"\"\"Load both FAISS index and metadata\"\"\"\n",
    "        if not os.path.exists(f\"{file_path}.faiss\"):\n",
    "            raise FileNotFoundError(f\"Index file {file_path}.faiss not found\")\n",
    "        \n",
    "        if not os.path.exists(f\"{file_path}_metadata.pkl\"):\n",
    "            raise FileNotFoundError(f\"Metadata file {file_path}_metadata.pkl not found\")\n",
    "        \n",
    "        # Load FAISS index\n",
    "        self.index = faiss.read_index(f\"{file_path}.faiss\")\n",
    "        \n",
    "        # Load metadata\n",
    "        with open(f\"{file_path}_metadata.pkl\", 'rb') as f:\n",
    "            metadata = pickle.load(f)\n",
    "        \n",
    "        self.chunks_dict = metadata['chunks_dict']\n",
    "        self.dimension = metadata['dimension']\n",
    "        self.total_vectors = metadata['total_vectors']\n",
    "        self.index_type = metadata['index_type']\n",
    "        \n",
    "        # Load enhanced attributes if they exist (backward compatibility)\n",
    "        self.docstore = metadata.get('docstore', None)\n",
    "        self.index_to_docstore_id = metadata.get('index_to_docstore_id', None)\n",
    "        self.documents = metadata.get('documents', None)\n",
    "        \n",
    "        # Set embedder model if provided\n",
    "        if embedder_model:\n",
    "            self.embedder_model = embedder_model\n",
    "        \n",
    "        print(f\"[FAISS] Index loaded: {self.total_vectors} vectors, dim {self.dimension}\")\n",
    "        if self.docstore is not None:\n",
    "            print(f\"[FAISS] Enhanced docstore mode enabled\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def set_embedder_model(self, embedder_model):\n",
    "        \"\"\"Set or update the embedder model\"\"\"\n",
    "        self.embedder_model = embedder_model\n",
    "        return self\n",
    "    \n",
    "    def get_stats(self):\n",
    "        \"\"\"Get index statistics\"\"\"\n",
    "        return {\n",
    "            'total_vectors': self.total_vectors,\n",
    "            'dimension': self.dimension,\n",
    "            'index_type': self.index_type,\n",
    "            'has_embedder': self.embedder_model is not None,\n",
    "            'has_docstore': self.docstore is not None,\n",
    "            'has_documents': self.documents is not None\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5f5d36",
   "metadata": {},
   "source": [
    "### LLM Abstract Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2c89f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLLM(ABC):\n",
    "    def __init__(self, model_name, cache_folder):\n",
    "        self.model_name = model_name\n",
    "        self.cache_folder = cache_folder\n",
    "        self.device = ('cpu'\n",
    "            # 'cuda' if torch.cuda.is_available()\n",
    "            # else 'mps' if torch.backends.mps.is_available()\n",
    "            # else 'cpu'\n",
    "        )\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_model(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class OLLAMA_LLM(BaseLLM):\n",
    "    def __init__(self, model_name, cache_folder):\n",
    "        super().__init__(model_name, cache_folder)\n",
    "\n",
    "    def load_model(self):\n",
    "        model = Ollama(model=self.model_name, temperature=0.3, num_ctx=4096)\n",
    "        return model\n",
    "\n",
    "\n",
    "class Hugging_Face_LLM(BaseLLM):\n",
    "    def __init__(self, model_name, cache_folder):\n",
    "        super().__init__(model_name, cache_folder)\n",
    "\n",
    "    def load_model(self):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            self.model_name,\n",
    "            cache_dir=self.cache_folder\n",
    "        )\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            self.model_name,\n",
    "            cache_dir=self.cache_folder,\n",
    "            torch_dtype=torch.float16 if self.device == \"cuda\" else torch.float32,\n",
    "            device_map=\"auto\"  \n",
    "        )\n",
    "        return model, tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ab7c4d",
   "metadata": {},
   "source": [
    "## Strategy Pattern Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71cb45df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskStrategy(ABC):\n",
    "    \"\"\"Abstract base class defining the strategy interface.\"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def run(self, *args, **kwargs):\n",
    "        \"\"\"Execute the strategy. Must be implemented by concrete strategies.\"\"\"\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5638e6",
   "metadata": {},
   "source": [
    "#### Chatting Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "469a4d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ChattingStrategy(TaskStrategy):\n",
    "    def __init__(self, llm, vector_store, embedder, top_k=5, return_sources=True):\n",
    "        self.llm = llm\n",
    "        self.vector_store = vector_store\n",
    "        self.vector_store.set_embedder_model(embedder)\n",
    "        self.top_k = top_k\n",
    "        self.return_sources = return_sources\n",
    "        self._build_chain()\n",
    "\n",
    "    def format_docs(self, docs):\n",
    "        return \"\\n\\n\".join(\n",
    "            f\"[Source {i} | PDF {doc.metadata.get('pdf_id', '?')}]: {doc.page_content}\"\n",
    "            for i, doc in enumerate(docs, 1)\n",
    "        )\n",
    "\n",
    "    def _build_chain(self):\n",
    "        prompt_template = \"\"\"You are a helpful assistant. Use the following context to answer the question.\n",
    "\n",
    "            Context:\n",
    "            {context}\n",
    "\n",
    "            Question: {question}\n",
    "\n",
    "            Please provide a comprehensive answer based on the context above. You MUST follow this exact format:\n",
    "\n",
    "            RESPONSE:\n",
    "            [Your main answer here]\n",
    "\n",
    "            REASONING:\n",
    "            [Explain your reasoning and how you used the context]\n",
    "\n",
    "            SOURCES:\n",
    "            [List the source numbers you referenced, for example: 1, 3, 5]\n",
    "            \"\"\"\n",
    "        \n",
    "        prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "        def retrieve_context(inputs):\n",
    "            docs = self.vector_store.get_relevant_documents(inputs[\"question\"], top_k=self.top_k)\n",
    "            return self.format_docs(docs)\n",
    "\n",
    "        self.chain = ({\n",
    "                \"context\": RunnableLambda(retrieve_context), \n",
    "                \"question\": RunnablePassthrough()\n",
    "            }\n",
    "            | prompt\n",
    "            | self.llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "\n",
    "    def parse_structured_response(self, response_text):\n",
    "        cleaned_response = re.sub(r'<think>.*?</think>', '', response_text, flags=re.DOTALL)\n",
    "        cleaned_response = re.sub(r'<[^>]+>', '', cleaned_response)\n",
    "        cleaned_response = re.sub(r'\\n\\s*\\n', '\\n\\n', cleaned_response.strip())\n",
    "\n",
    "        sections = {'response': '', 'reasoning': '', 'sources': ''}\n",
    "        current_section = None\n",
    "        current_content = []\n",
    "\n",
    "        lines = cleaned_response.split('\\n')\n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if line.upper().startswith('RESPONSE:'):\n",
    "                if current_section:\n",
    "                    sections[current_section] = '\\n'.join(current_content).strip()\n",
    "                current_section = 'response'\n",
    "                current_content = [line[9:].strip()]\n",
    "            elif line.upper().startswith('REASONING:'):\n",
    "                if current_section:\n",
    "                    sections[current_section] = '\\n'.join(current_content).strip()\n",
    "                current_section = 'reasoning'\n",
    "                current_content = [line[10:].strip()]\n",
    "            elif line.upper().startswith('SOURCES:'):\n",
    "                if current_section:\n",
    "                    sections[current_section] = '\\n'.join(current_content).strip()\n",
    "                current_section = 'sources'\n",
    "                current_content = [line[8:].strip()]\n",
    "            elif current_section and line:\n",
    "                current_content.append(line)\n",
    "\n",
    "        if current_section:\n",
    "            sections[current_section] = '\\n'.join(current_content).strip()\n",
    "\n",
    "        source_ids = [int(x) for x in re.findall(r'\\d+', sections['sources'])] if sections['sources'] else []\n",
    "\n",
    "        return {\n",
    "            'answer': sections['response'],\n",
    "            'reasoning': sections['reasoning'],\n",
    "            'sources': source_ids,\n",
    "            'raw_response': cleaned_response\n",
    "        }\n",
    "\n",
    "    def validate_input(self, question):\n",
    "        \"\"\"Validate that the question is a non-empty string.\"\"\"\n",
    "        return isinstance(question, str) and len(question.strip()) > 0\n",
    "\n",
    "    def run(self, question):\n",
    "        \"\"\"Main method to run the chain and parse result.\"\"\"\n",
    "        if not self.validate_input(question):\n",
    "            raise ValueError(\"Question must be a non-empty string\")\n",
    "        \n",
    "        response = self.chain.invoke({\"question\": question})\n",
    "\n",
    "        parsed = self.parse_structured_response(response)\n",
    "        print(f\"Parsed response: {parsed}\")  \n",
    "\n",
    "    \n",
    "        source_docs = self.vector_store.get_relevant_documents(question, top_k=self.top_k)\n",
    "        parsed['source_documents'] = source_docs\n",
    "        parsed['source_texts'] = [doc.page_content for doc in source_docs]\n",
    "        return parsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71af65b",
   "metadata": {},
   "source": [
    "#### Summerization Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "769e1c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizationStrategy(TaskStrategy):\n",
    "    def __init__(self, llm, template_file=\"SummarizationPrompts.yaml\"):\n",
    "        self.llm = llm\n",
    "        self.load_templates(template_file)\n",
    "    \n",
    "    def load_templates(self, template_file):\n",
    "        \"\"\"Load templates from YAML file.\"\"\"\n",
    "        with open(template_file, 'r', encoding='utf-8') as f:\n",
    "            data = yaml.safe_load(f)\n",
    "        self.summary_templates = data.get('summary_templates', {})\n",
    "        self.overview_templates = data.get('overview_templates', {})\n",
    "        \n",
    "    def validate_input(self, document):\n",
    "        \"\"\"Validate that the document is a non-empty string.\"\"\"\n",
    "        return isinstance(document, str) and len(document.strip()) > 0\n",
    "\n",
    "    def run(self, document, length=\"medium\", verbose=False, overview_level=None):\n",
    "        \"\"\"\n",
    "        Summarize the given document with customizable length and optional reasoning,\n",
    "        or create an overview at specified level and length.\n",
    "        \"\"\"\n",
    "        if overview_level:\n",
    "            return self._create_overview(document, overview_level, length, verbose)\n",
    "        return self._create_summary(document, length, verbose)\n",
    "    \n",
    "    def _create_overview(self, document, overview_level, length, verbose=False):\n",
    "        \"\"\"Create an overview of the document at the specified level and length.\"\"\"\n",
    "        template_type = \"with_reasoning\" if verbose else \"base\"\n",
    "        prompt_text = self.overview_templates[overview_level][length][template_type]\n",
    "        \n",
    "        prompt_template = ChatPromptTemplate.from_messages([(\"system\", prompt_text)])\n",
    "        formatted_prompt = prompt_template.format(context=document)\n",
    "        \n",
    "        result = self.llm.invoke(formatted_prompt)\n",
    "  \n",
    "        print(result)\n",
    "        return result\n",
    "    \n",
    "    def _create_summary(self, document, length, verbose):\n",
    "        \"\"\"Create a regular summary of the document.\"\"\"\n",
    "        template_type = \"with_reasoning\" if verbose else \"base\"\n",
    "        prompt_text = self.summary_templates[length][template_type]\n",
    "        \n",
    "        prompt_template = ChatPromptTemplate.from_messages([(\"system\", prompt_text)])\n",
    "        formatted_prompt = prompt_template.format(context=document)\n",
    "        \n",
    "        result = self.llm.invoke(formatted_prompt)\n",
    "   \n",
    "        print(result)\n",
    "        return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab426167",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Summarization_Rag_Strategy(TaskStrategy):\n",
    "    def __init__(self, llm,retriever):\n",
    "        self.llm = llm\n",
    "        self.retriever=retriever\n",
    "        self.prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"\n",
    "            You are a helpful assistant.\n",
    "\n",
    "            The user has provided a topic: \"{user_prompt}\"\n",
    "\n",
    "            Based on this, summarize the following retrieved document chunks using the format below. Only use information present in the document chunks — do not rely on prior knowledge or assumptions.\n",
    "\n",
    "            **Main Topic:** [One sentence describing what this document is about]\n",
    "\n",
    "            **Key Points:**\n",
    "            - [Most important point]\n",
    "            - [Second most important point]  \n",
    "            - [Third most important point]\n",
    "\n",
    "            **Details:** [Supporting information, numbers]\n",
    "\n",
    "            **Conclusion:** [Main takeaway or implication]\n",
    "\n",
    "            Document Chunks:\n",
    "            {context}\n",
    "            \"\"\")\n",
    "                    ])\n",
    "\n",
    "    def validate_input(self, documents):\n",
    "        \"\"\"Validate that the input is a non-empty list of Document objects.\"\"\"\n",
    "        return isinstance(documents, list) and all(isinstance(doc, Document) for doc in documents)\n",
    "\n",
    "    def run(self, prompt):\n",
    "        \"\"\"Retrieve and summarize relevant chunks.\"\"\"\n",
    "        similar_chunks = self.retriever.get_relevant_documents(prompt)\n",
    "\n",
    "        positively_correlated = [\n",
    "            chunk for chunk in similar_chunks\n",
    "            if chunk.metadata.get('similarity', 0) > 0.5\n",
    "        ]\n",
    "\n",
    "        if not positively_correlated:\n",
    "            raise ValueError(\"No chunks above similarity threshold.\")\n",
    "\n",
    "        combined_text = \"\\n\\n\".join([doc.page_content for doc in positively_correlated])\n",
    "\n",
    "\n",
    "        formatted_prompt = self.prompt.format(\n",
    "            user_prompt=prompt,\n",
    "            context=combined_text\n",
    "        )\n",
    "        result = self.llm.invoke(formatted_prompt)\n",
    "\n",
    "        print(result)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deff017",
   "metadata": {},
   "source": [
    "#### Question Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0bade4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionStrategy(TaskStrategy):\n",
    "    def __init__(self, llm, complexity=\"medium\"):\n",
    "        self.llm = llm\n",
    "        self.complexity = complexity\n",
    "        self._set_prompt()\n",
    "    \n",
    "    def _set_prompt(self):\n",
    "        complexity_instructions = {\n",
    "            \"easy\": \"Generate simple, basic questions that test understanding of key facts and definitions.\",\n",
    "            \"medium\": \"Generate moderately challenging questions that require analysis and understanding of concepts.\",\n",
    "            \"hard\": \"Generate complex questions that require critical thinking, analysis, and synthesis of information.\"\n",
    "        }\n",
    "        \n",
    "        instruction = complexity_instructions.get(self.complexity, complexity_instructions[\"medium\"])\n",
    "        \n",
    "        self.prompt = ChatPromptTemplate.from_template(f\"\"\"\n",
    "        You are a helpful assistant tasked with generating question-answer pairs for study purposes.\n",
    "\n",
    "        Text:\n",
    "        {{context}}\n",
    "\n",
    "        {instruction}\n",
    "        Generate {{Questions}} meaningful questions based only on the above text. \n",
    "\n",
    "        IMPORTANT: Format your output exactly as shown below with no additional text, explanations, or formatting:\n",
    "\n",
    "        Q1: [question text]\n",
    "        Q2: [question text]\n",
    "        Q3: [question text]\n",
    "        \"\"\")\n",
    "        self.qa_chain = self.prompt | self.llm | StrOutputParser()\n",
    "\n",
    "\n",
    "    def set_complexity(self, complexity):\n",
    "        \"\"\"Change complexity level with synonym mapping and fuzzy matching.\"\"\"\n",
    "        import difflib\n",
    "        \n",
    "        complexity = complexity.lower().strip()\n",
    "        \n",
    "        # Handle synonyms first\n",
    "        synonyms = {\n",
    "            \"challenging\": \"hard\", \"difficult\": \"hard\", \"tough\": \"hard\",\n",
    "            \"simple\": \"easy\", \"basic\": \"easy\", \"beginner\": \"easy\", \n",
    "            \"moderate\": \"medium\", \"average\": \"medium\", \"normal\": \"medium\"\n",
    "        }\n",
    "        \n",
    "        if complexity in synonyms:\n",
    "            self.complexity = synonyms[complexity]\n",
    "            self._set_prompt()\n",
    "            return\n",
    "        \n",
    "        # Check exact match\n",
    "        valid_options = [\"easy\", \"medium\", \"hard\"]\n",
    "        if complexity in valid_options:\n",
    "            self.complexity = complexity\n",
    "            self._set_prompt()\n",
    "            return\n",
    "        \n",
    "        # Fuzzy matching against synonyms first\n",
    "        all_options = list(synonyms.keys()) + valid_options\n",
    "        matches = difflib.get_close_matches(complexity, all_options, n=1, cutoff=0.6)\n",
    "        \n",
    "        if matches:\n",
    "            best_match = matches[0]\n",
    "            similarity = difflib.SequenceMatcher(None, complexity, best_match).ratio()\n",
    "            print(f\"'{complexity}' matched to '{best_match}' ({similarity:.0%} confidence)\")\n",
    "            \n",
    "            # Map to final complexity\n",
    "            final_complexity = synonyms.get(best_match, best_match)\n",
    "            self.complexity = final_complexity\n",
    "            self._set_prompt()\n",
    "        else:\n",
    "            raise ValueError(\"Please use: 'easy', 'medium', 'hard', or synonyms like 'challenging', 'simple'\")\n",
    "\n",
    "\n",
    "\n",
    "    def parse_qa_pairs(self, qa_output):\n",
    "        qa_pairs = []\n",
    "        lines = qa_output.strip().split('\\n')\n",
    "        i = 0\n",
    "        while i < len(lines):\n",
    "            q_match = re.match(r'Q(\\d+):\\s*(.+)', lines[i])\n",
    "            if q_match and i + 1 < len(lines):\n",
    "                question = q_match.group(2).strip()\n",
    "                a_match = re.match(f'A{q_match.group(1)}:\\s*(.+)', lines[i + 1])\n",
    "                if a_match:\n",
    "                    answer = a_match.group(1).strip()\n",
    "                    qa_pairs.append({'question': question, 'answer': answer})\n",
    "                    i += 2\n",
    "                else:\n",
    "                    i += 1\n",
    "            else:\n",
    "                i += 1\n",
    "        return qa_pairs\n",
    "\n",
    "    def validate_input(self, doc):\n",
    "        \"\"\"Validate that the document is a Document instance with content.\"\"\"\n",
    "        return (isinstance(doc, Document) and \n",
    "                hasattr(doc, 'page_content') and \n",
    "                len(doc.page_content.strip()) > 0)\n",
    "    \n",
    "    def run(self, doc, questions, complexity='simple'):\n",
    "        \"\"\"Generate questions from the given document.\"\"\"\n",
    "        if not self.validate_input(doc):\n",
    "            raise ValueError(\"Input must be a Document with non-empty page_content\")\n",
    "        \n",
    "        # Update complexity if provided\n",
    "        if complexity is not None:\n",
    "            self.set_complexity(complexity)\n",
    "            \n",
    "        try:\n",
    "            qa_output = self.qa_chain.invoke({\"context\": doc.page_content,\"Questions\":questions})\n",
    "            parsed_qa = self.parse_qa_pairs(qa_output)\n",
    "            print(qa_output)\n",
    "            print(parsed_qa)\n",
    "\n",
    "            return {\n",
    "                \"pdf_id\": doc.metadata.get(\"pdf_id\"),\n",
    "                \"chunk_id\": doc.metadata.get(\"chunk_id\"),\n",
    "                \"text\": doc.page_content,\n",
    "                \"qa_output\": qa_output,\n",
    "                \"parsed_qa\": parsed_qa\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ QA generation failed for Document {doc.metadata}: {e}\")\n",
    "            return None\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71a15e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaskProcessor:\n",
    "    \"\"\"Context class that uses different task strategies.\"\"\"\n",
    "    \n",
    "    def __init__(self, strategy=None):  \n",
    "        self._strategy = strategy      \n",
    "    \n",
    "    @property\n",
    "    def strategy(self):\n",
    "        return self._strategy\n",
    "         \n",
    "    @strategy.setter\n",
    "    def strategy(self, strategy):\n",
    "        self._strategy = strategy\n",
    "         \n",
    "    def execute_task(self, *args, **kwargs):\n",
    "        if self._strategy is None:      # ✅ Add this check\n",
    "            raise ValueError(\"No strategy set\")\n",
    "        return self._strategy.run(*args, **kwargs)\n",
    "         \n",
    "    def switch_strategy(self, new_strategy):\n",
    "        self.strategy = new_strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a47f073",
   "metadata": {},
   "source": [
    "## Classes Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "785f0200",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Total Chunks: 16\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Testing cell\n",
    "paths=[\"Market Research Report_extracted_text.json\"]\n",
    "docs=JSONPreprocessor()\n",
    "data=docs.process_documents_from_files(paths)\n",
    "individual_documents = [ Document(page_content=pdf.page_content, metadata={\"pdf_id\": i})\n",
    "    for i, pdf in enumerate(data) if pdf.page_content\n",
    "]\n",
    "chunked_docs=docs.chunk_documents(individual_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c14c74f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken to process:   2.896174907684326\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "multilingual_embedder=MultilingualEmbedder(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", batch_size=32)\n",
    "end=time.time()\n",
    "print(\"Time Taken to process:  \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5194a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken to process:   0.00013494491577148438\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "llm=OLLAMA_LLM('llama3:8b','llm_cache').load_model()\n",
    "end=time.time()\n",
    "print(\"Time Taken to process:  \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6187b37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start=time.time()\n",
    "# basic_fais=FAISSBasic(multilingual_embedder)\n",
    "# basic_fais.create_vector_store(chunked_docs)\n",
    "# end=time.time()\n",
    "# print(\"Time Taken to process:  \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "431ed67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FAISS] Created index with 16 vectors of dim 384\n",
      "Time Taken to process:   19.159896850585938\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "fais_improved = FAISSImproved()\n",
    "fais_improved.set_embedder_model(multilingual_embedder)\n",
    "fais_improved.create_vector_store(chunked_docs)\n",
    "end=time.time()\n",
    "print(\"Time Taken to process:  \", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c3cb1e",
   "metadata": {},
   "source": [
    "#### Strategy implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6d297857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken to process:   0.01162099838256836\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "chatting_strategy = ChattingStrategy(llm, fais_improved, multilingual_embedder)\n",
    "summarization_strategy = SummarizationStrategy(llm)\n",
    "question_strategy = QuestionStrategy(llm)\n",
    "rag_summary=Summarization_Rag_Strategy(llm,fais_improved)\n",
    "processor = TaskProcessor()\n",
    "end=time.time()\n",
    "print(\"Time Taken to process:  \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e86984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processor.strategy=chatting_strategy \n",
    "# processor.execute_task(\"Which translator charges users with credits?\")\n",
    "# end=time.time()\n",
    "# print(\"Time Taken to process:  \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "91545baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Query embedding final shape: (1, 384)\n",
      "[DEBUG] Index dimension: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'similarity': 0.28096646070480347}, page_content='This feature enables users to compare, review, and edit translations in real time, enhancing accuracy and usability for both professional and casual users. These recommended features address critical gaps in current tools, such as limited editing capabilit ies, lack of flexible OCR options, insufficient support for domain -specific or tone - adjusted translations, absence of advanced translation modes, and the need for intuitive review interfaces. Implementing these enhancements could significantly improve the functionality and market competitiveness of document translation tools.'),\n",
       " Document(metadata={'similarity': 0.19255179166793823}, page_content='• 5 editable file translations per user/month in tota l. • Upload files up to 10 MB • Tone /informal tone is available . Pro Advanced $28.74/user/ month (Paid annually ) For individuals & teams • 20 files/month . • 5 editable file translations per user/month in tota l. • Upload files up to 20 MB . • Tone /informal tone is available . Pro Ultimate $57.49 /user/ month (Paid annually ) For individuals & teams • 20 files/month . • 5 editable file translations per user/month in tota l. • Upload files up to 20 MB . • Tone /informal tone is available . Doclingo Premium 7-Day $2.29/7 -Day • 250,000 chars. Monthly limit. • No daily limit . • No number of tra ns. Limit. • File size: 500 MB . • Trans. Engine : ChatGPT/Gemini /Deepseek/Claude . Premium + 7- Day $2.99/7-Day • 500,000 chars. Monthly limit • No daily limit . • No number of tra ns. Limit. • File size: 500 MB . • Trans. Engine : ChatGPT/Gemini /Deepseek/Claude . Premium 30- Day $7.59/M • 1M chars. Monthly limit'),\n",
       " Document(metadata={'similarity': 0.1843949407339096}, page_content='Offer a selection of LLMs ca tegorized by subscription plans to accommodate varying user needs and budgets. 2. AI PDF Summarization: Provide automated summarization of PDF content, enabling users to quickly grasp key points without reading entire documents. 3. AI Question Generator: Generat e relevant questions based on PDF content, supporting educational, training, or analytical use cases. 4. AI Instructions: Allow users to input custom prompts or guidelines for the AI engine to follow during translation, ensuring translations align with specif ic requirements or preferences. 5. Domain -Specific Translation: Incorporate smart detection or a predefined list of domains (e.g., banking, accounting, law, physics) to enhance translation accuracy for specialized documents. 6. Tone Customization: Enable smart d etection or manual selection of tone (e.g., formal, friendly) to tailor translations to the intended audience or context.'),\n",
       " Document(metadata={'similarity': 0.18026694655418396}, page_content='• Process Modes 1. Professional Translation: The AI automatically selects the optimal style and format for the translation based on the do cument’s context, audience, and purpose. For example, legal documents would adopt a formal tone with precise terminology, while marketing materials might use a persuasive, audience -friendly style, ensuring contextually appropriate and high - quality translat ions. 2. Paraphrase: Rephrase text or specific sections of a document while preserving the original meaning. This mode is ideal for simplifying complex text, adapting content for different audiences, or avoiding repetitive phrasing, such as rephrasing a techn ical manual for non - expert readers . • Split -View Translation Interface Provide a split -screen interface displaying the original document on the left and the translated document on the right, with synchronized page -by-page scrolling similar to a PDF viewer. This feature enables users to compare, review, and edit translations in real time, enhancing accuracy and usability for both professional and casual users'),\n",
       " Document(metadata={'similarity': 0.17683957517147064}, page_content='TranslaDocs • Cons: o No OCR support . o No Arabic language support . SmallPDF • Cons: o No OCR support . Doclingo • Pros: o Supports OCR . o Good performance for Arabic to English scanned documents . • Cons: o Fails with complex image tables . o Does not preserve RTL when translating from English to Arabic . DeepL • Pros: o Excellent performance for English OCR . • Cons: o Does not support Arabic OCR. Translated documents can be found here : DeepL Summary of Findings: The tools demonstrated varied performance across key criteria. Some excelled in specific areas, such as translation accuracy or affordability, while others lagged in advanced features like robust language support or seamless integration with existing workf lows. Pricing models also ranged widely, catering to different user segments from cost -conscious individuals to enterprises requiring premium functionalities.')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fais_improved.get_relevant_documents(\"Editiors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0ffb3c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(processor.strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0417164f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Query embedding final shape: (1, 384)\n",
      "[DEBUG] Index dimension: 384\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No chunks above similarity threshold.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m processor\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m=\u001b[39mrag_summary\n\u001b[0;32m----> 2\u001b[0m summary\u001b[38;5;241m=\u001b[39m\u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEditiors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 18\u001b[0m, in \u001b[0;36mTaskProcessor.execute_task\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:      \u001b[38;5;66;03m# ✅ Add this check\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo strategy set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[28], line 43\u001b[0m, in \u001b[0;36mSummarization_Rag_Strategy.run\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m     37\u001b[0m positively_correlated \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     38\u001b[0m     chunk \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m similar_chunks\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunk\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilarity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m     40\u001b[0m ]\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m positively_correlated:\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo chunks above similarity threshold.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m combined_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([doc\u001b[38;5;241m.\u001b[39mpage_content \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m positively_correlated])\n\u001b[1;32m     48\u001b[0m formatted_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     49\u001b[0m     user_prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m     50\u001b[0m     context\u001b[38;5;241m=\u001b[39mcombined_text\n\u001b[1;32m     51\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: No chunks above similarity threshold."
     ]
    }
   ],
   "source": [
    "processor.strategy=rag_summary\n",
    "summary=processor.execute_task(\"Editiors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "96fbc482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Query embedding final shape: (1, 384)\n",
      "[DEBUG] Index dimension: 384\n",
      "Parsed response: {'answer': 'Translation websites can be evaluated based on their features and capabilities in translating documents accurately, efficiently, and cost-effectively across languages such as Arabic, French, and English. The analysis reveals that no single tool fully meets all requirements for preserving layout and handling OCR for scanned documents.', 'reasoning': \"The context provides insights into the market research report's findings on document translation tools. It highlights the limitations of current tools, including limited editing capabilities, lack of flexible OCR options, insufficient support for domain-specific or tone-adjusted translations, absence of advanced translation modes, and need for intuitive review interfaces. The recommended features aim to address these gaps and improve functionality, user experience, and translation quality.\", 'sources': [1, 3, 4], 'raw_response': \"RESPONSE:\\nTranslation websites can be evaluated based on their features and capabilities in translating documents accurately, efficiently, and cost-effectively across languages such as Arabic, French, and English. The analysis reveals that no single tool fully meets all requirements for preserving layout and handling OCR for scanned documents.\\n\\nREASONING:\\nThe context provides insights into the market research report's findings on document translation tools. It highlights the limitations of current tools, including limited editing capabilities, lack of flexible OCR options, insufficient support for domain-specific or tone-adjusted translations, absence of advanced translation modes, and need for intuitive review interfaces. The recommended features aim to address these gaps and improve functionality, user experience, and translation quality.\\n\\nSOURCES:\\n1, 3, 4\"}\n",
      "[DEBUG] Query embedding final shape: (1, 384)\n",
      "[DEBUG] Index dimension: 384\n"
     ]
    }
   ],
   "source": [
    "processor.strategy=chatting_strategy\n",
    "summary=processor.execute_task(\"Translation websites \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0c0020f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Translation websites can be evaluated based on their features and capabilities in translating documents accurately, efficiently, and cost-effectively across languages such as Arabic, French, and English. The analysis reveals that no single tool fully meets all requirements for preserving layout and handling OCR for scanned documents.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a5666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5874e4d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "run() got an unexpected keyword argument 'length'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, document \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(individual_documents):\n\u001b[1;32m      4\u001b[0m     doc_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlong\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     doc_end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDocument[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] processing time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdoc_end_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mdoc_start_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[14], line 18\u001b[0m, in \u001b[0;36mTaskProcessor.execute_task\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:      \u001b[38;5;66;03m# ✅ Add this check\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo strategy set\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: run() got an unexpected keyword argument 'length'"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for index, document in enumerate(individual_documents):\n",
    "    doc_start_time = time.time()\n",
    "    \n",
    "    processor.execute_task(document,length='long',verbose=True)\n",
    "    \n",
    "    doc_end_time = time.time()\n",
    "    print(f\"Document[{index}] processing time: {doc_end_time - doc_start_time:.2f} seconds\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"Total processing time:\", end_time - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0f6ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.QuestionStrategy object at 0x380610d30>\n"
     ]
    }
   ],
   "source": [
    "processor.strategy=question_strategy\n",
    "print(processor.strategy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8def0e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the 20 simple questions that test understanding of key facts and definitions based on the provided text:\n",
      "\n",
      "Q1: What is the primary focus of this market research report?\n",
      "Q2: Which languages are supported by the document translation tools evaluated in this report?\n",
      "Q3: What are the five test cases used to evaluate the document translation tools?\n",
      "Q4: Which tool lacks OCR capabilities?\n",
      "Q5: What is the main issue with Doctranslator's handling of mixed language content?\n",
      "Q6: Which tool provides OCR functionality but has slow processing times?\n",
      "Q7: What feature does TranslaDocs lack?\n",
      "Q8: Which tool offers limited translation support and no OCR capabilities?\n",
      "Q9: What is the primary limitation of Doclingo's performance in English to Arabic translations?\n",
      "Q10: Which tool excels in English OCR but does not support Arabic OCR?\n",
      "Q11: What are the three recommended editing features for document translation tools?\n",
      "Q12: What is the purpose of the \"Split PDF\" feature?\n",
      "Q13: Which tool provides a split-view translation interface?\n",
      "Q14: What is the main benefit of Doctranslate.io's Topup-50 plan?\n",
      "Q15: How many credits does the Personal Subscription plan provide per year?\n",
      "Q16: What is the maximum file size allowed for uploads in Doclingo's Premium 7-Day plan?\n",
      "Q17: Which tool has a processing time of 1-3 minutes for OCR-based translations?\n",
      "Q18: What is the primary limitation of TranslaDocs' performance in handling Arabic language content?\n",
      "Q19: How many characters are included in Doclingo's Premium + 30-Day plan?\n",
      "Q20: What is the main difference between Doctranslator and Doctranslate.io in terms of OCR support?\n",
      "[]\n",
      "Document[1] processing time: 20.36 seconds\n",
      "Here are the 20 questions:\n",
      "\n",
      "Q1: What is Monday.com?\n",
      "Q2: Which platform offers AI-powered drawing splitting and indexing?\n",
      "Q3: What is PMWeb's strong point in terms of cost control, scheduling, and portfolio-wide visibility?\n",
      "Q4: Which platform has a steep learning curve?\n",
      "Q5: What is Aconex's strength in structured communication, transmittals, and formal document control?\n",
      "Q6: Which platform offers automated submittals, AI-powered drawing management, and integrated bid handling?\n",
      "Q7: What is the main difference between Monday.com and Wrike?\n",
      "Q8: Which platform has a feature matrix that quantifies how well each platform supports a core set of functionalities?\n",
      "Q9: What is Procore's unique selling point in terms of construction-focused toolkit?\n",
      "Q10: Which platform offers OCR-based document processing?\n",
      "Q11: What is the primary function of Ra Power Management (RaPM)?\n",
      "Q12: Which platform has a role-based task assignment feature?\n",
      "Q13: What is the main difference between Aconex and Procore?\n",
      "Q14: Which platform has a strong point in terms of financial oversight?\n",
      "Q15: What is Monday.com's strength in terms of dashboards for tracking deadlines and project progress?\n",
      "Q16: Which platform offers version control and submittal coordination features?\n",
      "Q17: What is the primary function of SenseHawk?\n",
      "Q18: Which platform has a feature that allows users to compare any two revisions on-screen?\n",
      "Q19: What is PMWeb's strength in terms of portfolio-wide visibility?\n",
      "Q20: Which platform has a feature that tracks status in real-time, updating fields like \"Submitted for Review\" or \"Approved\"?\n",
      "[]\n",
      "Document[2] processing time: 25.35 seconds\n",
      "Time Taken to process:   45.715123891830444\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "for index, document in enumerate(individual_documents):\n",
    "    doc_start_time = time.time()\n",
    "    processor.execute_task(document,20)\n",
    "    doc_end_time = time.time()\n",
    "    print(f\"Document[{index+1}] processing time: {doc_end_time - doc_start_time:.2f} seconds\")\n",
    "end=time.time()\n",
    "print(\"Time Taken to process:  \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f63bdb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'challenshing' matched to 'challenging' (87% confidence)\n",
      "Here are the 20 complex questions based on the provided text:\n",
      "\n",
      "Q1: What are the key features evaluated in this market research report to assess document translation tools?\n",
      "\n",
      "Q2: Which tool offers free services with good layout preservation for English to Arabic translations and effective handling of text directionality?\n",
      "\n",
      "Q3: How does Doctranslator handle mixed language content, and what limitations does it have?\n",
      "\n",
      "Q4: What are the test cases conducted for each language in this report, and why are they important?\n",
      "\n",
      "Q5: Which tool provides OCR functionality but suffers from slow processing times and poor layout preservation?\n",
      "\n",
      "Q6: What is the main limitation of TranslaDocs, according to this report?\n",
      "\n",
      "Q7: How does SmallPDF handle translation support, and what are its limitations?\n",
      "\n",
      "Q8: What are the recommended features for enhancing document translation tools, as suggested in this report?\n",
      "\n",
      "Q9: How can AI-powered features improve the functionality of document translation tools?\n",
      "\n",
      "Q10: Which tool is excellent for English OCR but does not support Arabic OCR?\n",
      "\n",
      "Q11: What are the benefits and drawbacks of using Doctranslate.io's Topup plans?\n",
      "\n",
      "Q12: How do the pricing models of different tools cater to different user segments?\n",
      "\n",
      "Q13: What are the key findings from this market research report, and what implications do they have for document translation tool development?\n",
      "\n",
      "Q14: Which tool offers good performance for Arabic to English scanned documents but struggles with complex image tables?\n",
      "\n",
      "Q15: What is the main advantage of using Doclingo's Premium plans?\n",
      "\n",
      "Q16: How does the AI-powered summarization feature in this report support users' needs?\n",
      "\n",
      "Q17: What are the limitations of Doctranslator when translating from Arabic to English, and how do they impact its overall performance?\n",
      "\n",
      "Q18: Which tool provides a split-view translation interface for comparing and reviewing translations?\n",
      "\n",
      "Q19: What are the key differences between Doctranslate.io's Pro Starter and Pro Advanced plans?\n",
      "\n",
      "Q20: How can domain-specific translation features improve the accuracy of document translation tools?\n",
      "[]\n",
      "Document[1] processing time: 21.90 seconds\n",
      "'challenshing' matched to 'challenging' (87% confidence)\n",
      "Here are 20 complex questions that require critical thinking, analysis, and synthesis of information based on the provided text:\n",
      "\n",
      "Q1: What are the primary differences between Monday.com, Wrike, PMWeb, Aconex, and Procore in terms of their project management capabilities?\n",
      "\n",
      "Q2: How do the various platforms handle document approval workflows, and what are the implications for construction projects?\n",
      "\n",
      "Q3: What role does version control play in each platform's approach to managing documents, and how does this impact collaboration among stakeholders?\n",
      "\n",
      "Q4: Can you explain the concept of \"submittals\" in Procore, and how it differs from traditional project management tools?\n",
      "\n",
      "Q5: How do PMWeb, Aconex, and Procore support financial oversight and cost control for construction projects, and what are their respective strengths and limitations?\n",
      "\n",
      "Q6: What is the significance of \"bid management\" in Procore, and how does this feature impact the bidding process for construction projects?\n",
      "\n",
      "Q7: Can you compare and contrast the document management systems (DMS) offered by Monday.com, Wrike, PMWeb, Aconex, and Procore?\n",
      "\n",
      "Q8: How do the various platforms handle notifications and alerts, and what are the implications for project managers and stakeholders?\n",
      "\n",
      "Q9: What is the importance of \"project archiving\" in each platform's approach to managing construction projects, and how does this feature impact long-term project management?\n",
      "\n",
      "Q10: Can you explain the concept of \"overlaying drawings\" in Procore, and how this feature impacts the review process for construction projects?\n",
      "\n",
      "Q11: How do PMWeb, Aconex, and Procore support role-based task assignment and workflow approvals for construction projects?\n",
      "\n",
      "Q12: What are the primary differences between Monday.com and Wrike in terms of their project management capabilities, and which platform is more suitable for construction projects?\n",
      "\n",
      "Q13: Can you compare and contrast the reporting features offered by PMWeb, Aconex, and Procore, and what are the implications for project managers and stakeholders?\n",
      "\n",
      "Q14: How do the various platforms handle change orders and revisions in construction projects, and what are their respective strengths and limitations?\n",
      "\n",
      "Q15: What is the significance of \"AI-powered drawing management\" in Procore, and how does this feature impact the review process for construction projects?\n",
      "\n",
      "Q16: Can you explain the concept of \"transmittals\" in Aconex, and how this feature impacts the communication process for construction projects?\n",
      "\n",
      "Q17: How do PMWeb, Aconex, and Procore support collaboration among stakeholders, including contractors, consultants, and clients?\n",
      "\n",
      "Q18: What are the primary differences between Monday.com and Wrike in terms of their scalability and flexibility for large-scale construction projects?\n",
      "\n",
      "Q19: Can you compare and contrast the cost control features offered by PMWeb, Aconex, and Procore, and what are the implications for project managers and stakeholders?\n",
      "\n",
      "Q20: How do the various platforms handle project scheduling and resource allocation for construction projects, and what are their respective strengths and limitations?\n",
      "[]\n",
      "Document[2] processing time: 35.65 seconds\n",
      "Time Taken to process:   57.5525918006897\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "for index, document in enumerate(individual_documents):\n",
    "    doc_start_time = time.time()\n",
    "    processor.execute_task(document,20,'challenshing')\n",
    "    doc_end_time = time.time()\n",
    "    print(f\"Document[{index+1}] processing time: {doc_end_time - doc_start_time:.2f} seconds\")\n",
    "end=time.time()\n",
    "print(\"Time Taken to process:  \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea967662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 20 simple and basic questions that test understanding of key facts and definitions based on the provided text:\n",
      "\n",
      "Q1: What is the main focus of this market research report?\n",
      "Q2: Which languages are supported by the document translation tools evaluated in this report?\n",
      "Q3: What are the key features evaluated in this report?\n",
      "Q4: What is OCR (Optical Character Recognition) support, and which tool lacks it?\n",
      "Q5: Which tool offers free services with good layout preservation for English to Arabic translations?\n",
      "Q6: What is the main limitation of Doctranslator's OCR capabilities?\n",
      "Q7: Which tool provides OCR functionality but suffers from slow processing times?\n",
      "Q8: What is the primary issue with TranslaDocs' translation accuracy?\n",
      "Q9: Which tool does not support Arabic language or OCR?\n",
      "Q10: What is the pricing model for SmallPDF?\n",
      "Q11: Which tool supports OCR with good performance for Arabic to English scanned documents?\n",
      "Q12: What is the main limitation of Doclingo's OCR capabilities?\n",
      "Q13: Which tool offers excellent performance for English OCR but does not support Arabic OCR?\n",
      "Q14: What are the five recommended features for document translation tools?\n",
      "Q15: What is the purpose of the \"Chat with PDF\" feature in AI-Powered Features?\n",
      "Q16: Which tool provides a split-view translation interface?\n",
      "Q17: What is the main benefit of the \"Professional Translation\" process mode?\n",
      "Q18: Which tool offers a personal subscription plan?\n",
      "Q19: What is the maximum file size for uploading files to Doclingo Premium plans?\n",
      "Q20: Which tool has a monthly limit of 2M chars in its Premium + 30-Day plan?\n",
      "[]\n",
      "Document[1] processing time: 19.84 seconds\n",
      "Here are 20 simple questions that test understanding of key facts and definitions based on the provided text:\n",
      "\n",
      "Q1: What is the primary function of Monday.com?\n",
      "Q2: Which platform has a strong focus on cost control, scheduling, and portfolio-wide visibility?\n",
      "Q3: What is the main difference between Wrike and PMWeb?\n",
      "Q4: How does Aconex differ from Procore in terms of its features?\n",
      "Q5: What is the primary function of Ra Power Management (RaPM)?\n",
      "Q6: Which platform has a feature called \"Auto-changing status after submittals\"?\n",
      "Q7: What is the main difference between Monday.com and Wrike in terms of their features?\n",
      "Q8: How does Procore's Submittal Builder work?\n",
      "Q9: What is the purpose of the Specification Book in Procore?\n",
      "Q10: Which platform has a feature called \"Markup versions\"?\n",
      "Q11: What is the primary function of Payaca?\n",
      "Q12: How does Aconex handle formal document control and transmittals?\n",
      "Q13: What is the main difference between PMWeb and Procore in terms of their features?\n",
      "Q14: How does Monday.com support financial oversight?\n",
      "Q15: Which platform has a feature called \"Bids management\"?\n",
      "Q16: What is the primary function of SenseHawk?\n",
      "Q17: How does Wrike handle role assignment and approval workflows?\n",
      "Q18: What is the main difference between Procore and Aconex in terms of their features?\n",
      "Q19: How does PMWeb support project archiving?\n",
      "Q20: Which platform has a feature called \"Drawings tool\" with OCR engine?\n",
      "[]\n",
      "Document[2] processing time: 25.23 seconds\n",
      "Time Taken to process:   45.07068204879761\n"
     ]
    }
   ],
   "source": [
    "start=time.time()\n",
    "for index, document in enumerate(individual_documents):\n",
    "    doc_start_time = time.time()\n",
    "    processor.execute_task(document,20,'simple')\n",
    "    doc_end_time = time.time()\n",
    "    print(f\"Document[{index+1}] processing time: {doc_end_time - doc_start_time:.2f} seconds\")\n",
    "end=time.time()\n",
    "print(\"Time Taken to process:  \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4b6641",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
